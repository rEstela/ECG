{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2197f58-2f08-4983-949f-d5e18d465c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For Classification Report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# For Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# For K-Fold\n",
    "#from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5cf0fca-45da-4b93-9dc0-4b3a1d08c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary classification analysis\n",
    "def classification_metrics_binary(y_true, y_pred, model, fold):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    perc_tn, perc_fp, perc_fn, perc_tp = list(map(lambda x:x/len(y_true)*100, [tn, fp, fn, tp]))\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    false_positive_rate = fp/(tn+fp)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(tn+fp)\n",
    "    accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "    f1_score = 2*precision*sensitivity/(sensitivity+precision)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    return {\"model\":model, \"fold\": fold,\n",
    "            \"tn\":tn, \"fp\":fp, \"fn\":fn, \"tp\":tp, \"perc_tn\":perc_tn, \"perc_fp\":perc_fp, \n",
    "            \"perc_fn\":perc_fn, \"perc_tp\":perc_tp, \"sensitivity\":sensitivity, \n",
    "            \"tpr\":sensitivity, \"recall\":sensitivity, \"fpr\":false_positive_rate, \n",
    "            \"precision\":precision, \"ppv\":precision, \"specificity\":specificity, \n",
    "            \"tnr\":specificity,\"f1_score\":f1_score, \"auc\":auc_value, \"kappa\":kappa, \n",
    "            \"accuracy\":accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d083548e-9ad3-4995-8a62-7139fae1f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "def plot_confusion(y_true, y_pred):\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_name = ['Good', 'Bad']\n",
    "    cm = pd.DataFrame(cm, index=class_name, columns=class_name)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "\n",
    "    # Salva a figura como .eps\n",
    "    #plt.savefig('confusion_matrix_FAxNORMAL_preprocessed.eps', format='eps')\n",
    "\n",
    "    # Salva a figura como .png com 300 DPI\n",
    "    #plt.savefig('confusion_matrix_FAxNORMAL_preprocessed.png', format='png', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2303c1-6629-45e2-b0d3-90efdbc488fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 32\n",
    "\n",
    "# Método random forest estoura a memória. Utilizar o HPC para rodar.\n",
    "methods = { 'xgboost': xgboost.XGBClassifier(seed=RANDOM_SEED),\n",
    "            'logistic_regression': LogisticRegression(random_state=RANDOM_SEED),\n",
    "            'random_forest': RandomForestClassifier(random_state=RANDOM_SEED),\n",
    "            'gradient_boosting': GradientBoostingClassifier(random_state=RANDOM_SEED),\n",
    "            'svm': SVC(random_state=RANDOM_SEED),\n",
    "            'knn': KNeighborsClassifier(),\n",
    "            'decision_tree': DecisionTreeClassifier(random_state=RANDOM_SEED),\n",
    "            'naive_bayes': GaussianNB()\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6da871b-0cf2-4430-8aba-9373131119c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/estel/Documents/Python_Codes/'\n",
    "file = 'dataframe_cinc2011.csv'\n",
    "df = pd.read_csv(dir + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9498d6ff-8f0b-412b-a14c-df2ef0869711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iSQI</th>\n",
       "      <th>bSQI</th>\n",
       "      <th>fSQI</th>\n",
       "      <th>sSQI</th>\n",
       "      <th>kSQI</th>\n",
       "      <th>pSQI</th>\n",
       "      <th>zero_crossings_rate_sqi</th>\n",
       "      <th>mean_crossing_rate_sqi</th>\n",
       "      <th>find_max_lenght_repeated_true</th>\n",
       "      <th>flat_line_sqi</th>\n",
       "      <th>saturation_sqi</th>\n",
       "      <th>baseline_sqi</th>\n",
       "      <th>amplitude_sqi</th>\n",
       "      <th>rr_variability_sqi_mean</th>\n",
       "      <th>rr_variability_sqi_std</th>\n",
       "      <th>rr_variability_sqi_cv</th>\n",
       "      <th>power_sqi</th>\n",
       "      <th>bsqi</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.998</td>\n",
       "      <td>10.000</td>\n",
       "      <td>80.013002</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>4.726000</td>\n",
       "      <td>4.278000</td>\n",
       "      <td>0.905205</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.544039</td>\n",
       "      <td>-0.466121</td>\n",
       "      <td>19.392805</td>\n",
       "      <td>64.56</td>\n",
       "      <td>0.078016</td>\n",
       "      <td>0.039408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1.939037</td>\n",
       "      <td>1.867886</td>\n",
       "      <td>0.971778</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.690462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>-2.174674</td>\n",
       "      <td>9.449453</td>\n",
       "      <td>49.30</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.360</td>\n",
       "      <td>2.977677</td>\n",
       "      <td>1.656793</td>\n",
       "      <td>1.005111</td>\n",
       "      <td>0.277088</td>\n",
       "      <td>0.275679</td>\n",
       "      <td>0.912231</td>\n",
       "      <td>0.033376</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.278857</td>\n",
       "      <td>-0.668478</td>\n",
       "      <td>2.535006</td>\n",
       "      <td>45.08</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.042408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.243427</td>\n",
       "      <td>1.078492</td>\n",
       "      <td>0.497889</td>\n",
       "      <td>0.083689</td>\n",
       "      <td>0.168087</td>\n",
       "      <td>0.896940</td>\n",
       "      <td>0.804223</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>4.419841</td>\n",
       "      <td>25.069053</td>\n",
       "      <td>47.04</td>\n",
       "      <td>0.106821</td>\n",
       "      <td>0.067213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.046265</td>\n",
       "      <td>0.863515</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.839863</td>\n",
       "      <td>0.963011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>4.682297</td>\n",
       "      <td>20.321459</td>\n",
       "      <td>78.22</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1</td>\n",
       "      <td>2.618</td>\n",
       "      <td>10.000</td>\n",
       "      <td>96.460091</td>\n",
       "      <td>101.184824</td>\n",
       "      <td>2.161000</td>\n",
       "      <td>1.825000</td>\n",
       "      <td>0.844516</td>\n",
       "      <td>0.795078</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>0.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.486928</td>\n",
       "      <td>-1.396489</td>\n",
       "      <td>5.821627</td>\n",
       "      <td>56.62</td>\n",
       "      <td>0.096819</td>\n",
       "      <td>0.059812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.710963</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.158060</td>\n",
       "      <td>0.913264</td>\n",
       "      <td>0.817194</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0.24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.599578</td>\n",
       "      <td>3.107946</td>\n",
       "      <td>14.621376</td>\n",
       "      <td>69.52</td>\n",
       "      <td>0.043409</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023694</td>\n",
       "      <td>0.698364</td>\n",
       "      <td>0.815273</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.041080</td>\n",
       "      <td>0.906902</td>\n",
       "      <td>0.887943</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0.24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.624298</td>\n",
       "      <td>3.345171</td>\n",
       "      <td>16.979691</td>\n",
       "      <td>59.98</td>\n",
       "      <td>0.166833</td>\n",
       "      <td>0.126025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054890</td>\n",
       "      <td>0.520235</td>\n",
       "      <td>0.805273</td>\n",
       "      <td>0.076226</td>\n",
       "      <td>0.094658</td>\n",
       "      <td>0.926429</td>\n",
       "      <td>0.884870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.665089</td>\n",
       "      <td>4.245285</td>\n",
       "      <td>19.330689</td>\n",
       "      <td>71.56</td>\n",
       "      <td>0.074215</td>\n",
       "      <td>0.048410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.741833</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.970006</td>\n",
       "      <td>0.917078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  iSQI   bSQI      fSQI      sSQI       kSQI    pSQI  \\\n",
       "0             0  0.00    0.0  0.000000  0.000000   0.000000  100.00   \n",
       "1             1  0.20  100.0  0.544039 -0.466121  19.392805   64.56   \n",
       "2             2  0.16  100.0  0.005520 -2.174674   9.449453   49.30   \n",
       "3             3  0.30  100.0  0.278857 -0.668478   2.535006   45.08   \n",
       "4             4  0.20  100.0  0.619605  4.419841  25.069053   47.04   \n",
       "..          ...   ...    ...       ...       ...        ...     ...   \n",
       "993         993  0.04  100.0  0.237600  4.682297  20.321459   78.22   \n",
       "994         994  0.26  100.0  0.486928 -1.396489   5.821627   56.62   \n",
       "995         995  0.24  100.0  0.599578  3.107946  14.621376   69.52   \n",
       "996         996  0.24  100.0  0.624298  3.345171  16.979691   59.98   \n",
       "997         997  0.26  100.0  0.665089  4.245285  19.330689   71.56   \n",
       "\n",
       "     zero_crossings_rate_sqi  mean_crossing_rate_sqi  \\\n",
       "0                   0.000000                0.000000   \n",
       "1                   0.078016                0.039408   \n",
       "2                   0.030206                0.013203   \n",
       "3                   0.047009                0.042408   \n",
       "4                   0.106821                0.067213   \n",
       "..                       ...                     ...   \n",
       "993                 0.000800                0.000800   \n",
       "994                 0.096819                0.059812   \n",
       "995                 0.043409                0.031606   \n",
       "996                 0.166833                0.126025   \n",
       "997                 0.074215                0.048410   \n",
       "\n",
       "     find_max_lenght_repeated_true  flat_line_sqi  saturation_sqi  \\\n",
       "0                                1          9.998          10.000   \n",
       "1                                1          0.016           0.048   \n",
       "2                                1          0.012           0.360   \n",
       "3                                1          0.012           0.000   \n",
       "4                                1          0.016           0.000   \n",
       "..                             ...            ...             ...   \n",
       "993                              1          2.618          10.000   \n",
       "994                              1          0.022           0.000   \n",
       "995                              1          0.030           0.000   \n",
       "996                              1          0.020           0.000   \n",
       "997                              1          0.036           0.000   \n",
       "\n",
       "     baseline_sqi  amplitude_sqi  rr_variability_sqi_mean  \\\n",
       "0       80.013002       0.013002                 4.726000   \n",
       "1        1.939037       1.867886                 0.971778   \n",
       "2        2.977677       1.656793                 1.005111   \n",
       "3        0.243427       1.078492                 0.497889   \n",
       "4        0.046265       0.863515                 0.955333   \n",
       "..            ...            ...                      ...   \n",
       "993     96.460091     101.184824                 2.161000   \n",
       "994      0.100702       0.710963                 0.439300   \n",
       "995      0.023694       0.698364                 0.815273   \n",
       "996      0.054890       0.520235                 0.805273   \n",
       "997      0.020834       0.706087                 0.741833   \n",
       "\n",
       "     rr_variability_sqi_std  rr_variability_sqi_cv  power_sqi      bsqi  \\\n",
       "0                  4.278000               0.905205   0.755742  0.000000   \n",
       "1                  0.005202               0.005353   0.923708  0.690462   \n",
       "2                  0.277088               0.275679   0.912231  0.033376   \n",
       "3                  0.083689               0.168087   0.896940  0.804223   \n",
       "4                  0.008944               0.009362   0.839863  0.963011   \n",
       "..                      ...                    ...        ...       ...   \n",
       "993                1.825000               0.844516   0.795078  0.010157   \n",
       "994                0.069436               0.158060   0.913264  0.817194   \n",
       "995                0.033491               0.041080   0.906902  0.887943   \n",
       "996                0.076226               0.094658   0.926429  0.884870   \n",
       "997                0.019104               0.025753   0.970006  0.917078   \n",
       "\n",
       "     Labels  \n",
       "0       1.0  \n",
       "1       0.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "993     1.0  \n",
       "994     0.0  \n",
       "995     1.0  \n",
       "996     1.0  \n",
       "997     0.0  \n",
       "\n",
       "[998 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1410175-d361-41b6-b285-f001ad50ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Unnamed: 0', 'Labels'])\n",
    "y = df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1960c7db-5adb-4175-9f09-dab37cadd9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iSQI</th>\n",
       "      <th>bSQI</th>\n",
       "      <th>fSQI</th>\n",
       "      <th>sSQI</th>\n",
       "      <th>kSQI</th>\n",
       "      <th>pSQI</th>\n",
       "      <th>zero_crossings_rate_sqi</th>\n",
       "      <th>mean_crossing_rate_sqi</th>\n",
       "      <th>find_max_lenght_repeated_true</th>\n",
       "      <th>flat_line_sqi</th>\n",
       "      <th>saturation_sqi</th>\n",
       "      <th>baseline_sqi</th>\n",
       "      <th>amplitude_sqi</th>\n",
       "      <th>rr_variability_sqi_mean</th>\n",
       "      <th>rr_variability_sqi_std</th>\n",
       "      <th>rr_variability_sqi_cv</th>\n",
       "      <th>power_sqi</th>\n",
       "      <th>bsqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.998</td>\n",
       "      <td>10.000</td>\n",
       "      <td>80.013002</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>4.726000</td>\n",
       "      <td>4.278000</td>\n",
       "      <td>0.905205</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.544039</td>\n",
       "      <td>-0.466121</td>\n",
       "      <td>19.392805</td>\n",
       "      <td>64.56</td>\n",
       "      <td>0.078016</td>\n",
       "      <td>0.039408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1.939037</td>\n",
       "      <td>1.867886</td>\n",
       "      <td>0.971778</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.690462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>-2.174674</td>\n",
       "      <td>9.449453</td>\n",
       "      <td>49.30</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.360</td>\n",
       "      <td>2.977677</td>\n",
       "      <td>1.656793</td>\n",
       "      <td>1.005111</td>\n",
       "      <td>0.277088</td>\n",
       "      <td>0.275679</td>\n",
       "      <td>0.912231</td>\n",
       "      <td>0.033376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.278857</td>\n",
       "      <td>-0.668478</td>\n",
       "      <td>2.535006</td>\n",
       "      <td>45.08</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.042408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.243427</td>\n",
       "      <td>1.078492</td>\n",
       "      <td>0.497889</td>\n",
       "      <td>0.083689</td>\n",
       "      <td>0.168087</td>\n",
       "      <td>0.896940</td>\n",
       "      <td>0.804223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>4.419841</td>\n",
       "      <td>25.069053</td>\n",
       "      <td>47.04</td>\n",
       "      <td>0.106821</td>\n",
       "      <td>0.067213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.046265</td>\n",
       "      <td>0.863515</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.839863</td>\n",
       "      <td>0.963011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>4.682297</td>\n",
       "      <td>20.321459</td>\n",
       "      <td>78.22</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1</td>\n",
       "      <td>2.618</td>\n",
       "      <td>10.000</td>\n",
       "      <td>96.460091</td>\n",
       "      <td>101.184824</td>\n",
       "      <td>2.161000</td>\n",
       "      <td>1.825000</td>\n",
       "      <td>0.844516</td>\n",
       "      <td>0.795078</td>\n",
       "      <td>0.010157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.486928</td>\n",
       "      <td>-1.396489</td>\n",
       "      <td>5.821627</td>\n",
       "      <td>56.62</td>\n",
       "      <td>0.096819</td>\n",
       "      <td>0.059812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.710963</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.158060</td>\n",
       "      <td>0.913264</td>\n",
       "      <td>0.817194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.599578</td>\n",
       "      <td>3.107946</td>\n",
       "      <td>14.621376</td>\n",
       "      <td>69.52</td>\n",
       "      <td>0.043409</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023694</td>\n",
       "      <td>0.698364</td>\n",
       "      <td>0.815273</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.041080</td>\n",
       "      <td>0.906902</td>\n",
       "      <td>0.887943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.624298</td>\n",
       "      <td>3.345171</td>\n",
       "      <td>16.979691</td>\n",
       "      <td>59.98</td>\n",
       "      <td>0.166833</td>\n",
       "      <td>0.126025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054890</td>\n",
       "      <td>0.520235</td>\n",
       "      <td>0.805273</td>\n",
       "      <td>0.076226</td>\n",
       "      <td>0.094658</td>\n",
       "      <td>0.926429</td>\n",
       "      <td>0.884870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.665089</td>\n",
       "      <td>4.245285</td>\n",
       "      <td>19.330689</td>\n",
       "      <td>71.56</td>\n",
       "      <td>0.074215</td>\n",
       "      <td>0.048410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.741833</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.970006</td>\n",
       "      <td>0.917078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iSQI   bSQI      fSQI      sSQI       kSQI    pSQI  \\\n",
       "0    0.00    0.0  0.000000  0.000000   0.000000  100.00   \n",
       "1    0.20  100.0  0.544039 -0.466121  19.392805   64.56   \n",
       "2    0.16  100.0  0.005520 -2.174674   9.449453   49.30   \n",
       "3    0.30  100.0  0.278857 -0.668478   2.535006   45.08   \n",
       "4    0.20  100.0  0.619605  4.419841  25.069053   47.04   \n",
       "..    ...    ...       ...       ...        ...     ...   \n",
       "993  0.04  100.0  0.237600  4.682297  20.321459   78.22   \n",
       "994  0.26  100.0  0.486928 -1.396489   5.821627   56.62   \n",
       "995  0.24  100.0  0.599578  3.107946  14.621376   69.52   \n",
       "996  0.24  100.0  0.624298  3.345171  16.979691   59.98   \n",
       "997  0.26  100.0  0.665089  4.245285  19.330689   71.56   \n",
       "\n",
       "     zero_crossings_rate_sqi  mean_crossing_rate_sqi  \\\n",
       "0                   0.000000                0.000000   \n",
       "1                   0.078016                0.039408   \n",
       "2                   0.030206                0.013203   \n",
       "3                   0.047009                0.042408   \n",
       "4                   0.106821                0.067213   \n",
       "..                       ...                     ...   \n",
       "993                 0.000800                0.000800   \n",
       "994                 0.096819                0.059812   \n",
       "995                 0.043409                0.031606   \n",
       "996                 0.166833                0.126025   \n",
       "997                 0.074215                0.048410   \n",
       "\n",
       "     find_max_lenght_repeated_true  flat_line_sqi  saturation_sqi  \\\n",
       "0                                1          9.998          10.000   \n",
       "1                                1          0.016           0.048   \n",
       "2                                1          0.012           0.360   \n",
       "3                                1          0.012           0.000   \n",
       "4                                1          0.016           0.000   \n",
       "..                             ...            ...             ...   \n",
       "993                              1          2.618          10.000   \n",
       "994                              1          0.022           0.000   \n",
       "995                              1          0.030           0.000   \n",
       "996                              1          0.020           0.000   \n",
       "997                              1          0.036           0.000   \n",
       "\n",
       "     baseline_sqi  amplitude_sqi  rr_variability_sqi_mean  \\\n",
       "0       80.013002       0.013002                 4.726000   \n",
       "1        1.939037       1.867886                 0.971778   \n",
       "2        2.977677       1.656793                 1.005111   \n",
       "3        0.243427       1.078492                 0.497889   \n",
       "4        0.046265       0.863515                 0.955333   \n",
       "..            ...            ...                      ...   \n",
       "993     96.460091     101.184824                 2.161000   \n",
       "994      0.100702       0.710963                 0.439300   \n",
       "995      0.023694       0.698364                 0.815273   \n",
       "996      0.054890       0.520235                 0.805273   \n",
       "997      0.020834       0.706087                 0.741833   \n",
       "\n",
       "     rr_variability_sqi_std  rr_variability_sqi_cv  power_sqi      bsqi  \n",
       "0                  4.278000               0.905205   0.755742  0.000000  \n",
       "1                  0.005202               0.005353   0.923708  0.690462  \n",
       "2                  0.277088               0.275679   0.912231  0.033376  \n",
       "3                  0.083689               0.168087   0.896940  0.804223  \n",
       "4                  0.008944               0.009362   0.839863  0.963011  \n",
       "..                      ...                    ...        ...       ...  \n",
       "993                1.825000               0.844516   0.795078  0.010157  \n",
       "994                0.069436               0.158060   0.913264  0.817194  \n",
       "995                0.033491               0.041080   0.906902  0.887943  \n",
       "996                0.076226               0.094658   0.926429  0.884870  \n",
       "997                0.019104               0.025753   0.970006  0.917078  \n",
       "\n",
       "[998 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522efd61-b839-45ba-a203-3143ceddd98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      0.0\n",
       "      ... \n",
       "993    1.0\n",
       "994    0.0\n",
       "995    1.0\n",
       "996    1.0\n",
       "997    0.0\n",
       "Name: Labels, Length: 998, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e669018-eaad-415c-a02d-f628e3cadcf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost (798, 18) (798,) (200, 18) (200,)\n",
      "xgboost (798, 18) (798,) (200, 18) (200,)\n",
      "xgboost (798, 18) (798,) (200, 18) (200,)\n",
      "xgboost (799, 18) (799,) (199, 18) (199,)\n",
      "xgboost (799, 18) (799,) (199, 18) (199,)\n",
      "logistic_regression (798, 18) (798,) (200, 18) (200,)\n",
      "logistic_regression (798, 18) (798,) (200, 18) (200,)\n",
      "logistic_regression (798, 18) (798,) (200, 18) (200,)\n",
      "logistic_regression (799, 18) (799,) (199, 18) (199,)\n",
      "logistic_regression (799, 18) (799,) (199, 18) (199,)\n",
      "random_forest (798, 18) (798,) (200, 18) (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\anaconda3\\envs\\estudos\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n",
      "C:\\Users\\estel\\anaconda3\\envs\\estudos\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n",
      "C:\\Users\\estel\\anaconda3\\envs\\estudos\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\anaconda3\\envs\\estudos\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\anaconda3\\envs\\estudos\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest (798, 18) (798,) (200, 18) (200,)\n",
      "random_forest (798, 18) (798,) (200, 18) (200,)\n",
      "random_forest (799, 18) (799,) (199, 18) (199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest (799, 18) (799,) (199, 18) (199,)\n",
      "gradient_boosting (798, 18) (798,) (200, 18) (200,)\n",
      "gradient_boosting (798, 18) (798,) (200, 18) (200,)\n",
      "gradient_boosting (798, 18) (798,) (200, 18) (200,)\n",
      "gradient_boosting (799, 18) (799,) (199, 18) (199,)\n",
      "gradient_boosting (799, 18) (799,) (199, 18) (199,)\n",
      "svm (798, 18) (798,) (200, 18) (200,)\n",
      "svm (798, 18) (798,) (200, 18) (200,)\n",
      "svm (798, 18) (798,) (200, 18) (200,)\n",
      "svm (799, 18) (799,) (199, 18) (199,)\n",
      "svm (799, 18) (799,) (199, 18) (199,)\n",
      "knn (798, 18) (798,) (200, 18) (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn (798, 18) (798,) (200, 18) (200,)\n",
      "knn (798, 18) (798,) (200, 18) (200,)\n",
      "knn (799, 18) (799,) (199, 18) (199,)\n",
      "knn (799, 18) (799,) (199, 18) (199,)\n",
      "decision_tree (798, 18) (798,) (200, 18) (200,)\n",
      "decision_tree (798, 18) (798,) (200, 18) (200,)\n",
      "decision_tree (798, 18) (798,) (200, 18) (200,)\n",
      "decision_tree (799, 18) (799,) (199, 18) (199,)\n",
      "decision_tree (799, 18) (799,) (199, 18) (199,)\n",
      "naive_bayes (798, 18) (798,) (200, 18) (200,)\n",
      "naive_bayes (798, 18) (798,) (200, 18) (200,)\n",
      "naive_bayes (798, 18) (798,) (200, 18) (200,)\n",
      "naive_bayes (799, 18) (799,) (199, 18) (199,)\n",
      "naive_bayes (799, 18) (799,) (199, 18) (199,)\n"
     ]
    }
   ],
   "source": [
    "# Classificando K-FOLD\n",
    "resultados = []\n",
    "\n",
    "for method in methods.keys():\n",
    "    m = methods[method]\n",
    "    \n",
    "    # Número de folds desejado\n",
    "    num_folds = 5\n",
    "    \n",
    "    # Inicialize o objeto StratifiedKFold\n",
    "    stratkf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Loop sobre os k-folds\n",
    "    for idx, (train_idx, test_idx) in enumerate(stratkf.split(X, y)):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        print(method, X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        model = m.fit(X_train, y_train)\n",
    "        \n",
    "        # Faz predições no conjunto de teste\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Avalia o desempenho do modelo e armazena os resultados\n",
    "        results_fold = classification_metrics_binary(y_test, y_pred, method, idx)\n",
    "        resultados.append(results_fold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c5d941-09d7-4d1c-971e-978275ba7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'xgboost', 'fold': 0, 'tn': 136, 'fp': 19, 'fn': 42, 'tp': 3, 'perc_tn': 68.0, 'perc_fp': 9.5, 'perc_fn': 21.0, 'perc_tp': 1.5, 'sensitivity': 0.06666666666666667, 'tpr': 0.06666666666666667, 'recall': 0.06666666666666667, 'fpr': 0.12258064516129032, 'precision': 0.13636363636363635, 'ppv': 0.13636363636363635, 'specificity': 0.8774193548387097, 'tnr': 0.8774193548387097, 'f1_score': 0.08955223880597016, 'auc': 0.4720430107526882, 'kappa': -0.06830122591943977, 'accuracy': 0.695} \n",
      "\n",
      "{'model': 'xgboost', 'fold': 1, 'tn': 149, 'fp': 6, 'fn': 40, 'tp': 5, 'perc_tn': 74.5, 'perc_fp': 3.0, 'perc_fn': 20.0, 'perc_tp': 2.5, 'sensitivity': 0.1111111111111111, 'tpr': 0.1111111111111111, 'recall': 0.1111111111111111, 'fpr': 0.03870967741935484, 'precision': 0.45454545454545453, 'ppv': 0.45454545454545453, 'specificity': 0.9612903225806452, 'tnr': 0.9612903225806452, 'f1_score': 0.17857142857142855, 'auc': 0.5362007168458782, 'kappa': 0.09892262487757097, 'accuracy': 0.77} \n",
      "\n",
      "{'model': 'xgboost', 'fold': 2, 'tn': 139, 'fp': 16, 'fn': 41, 'tp': 4, 'perc_tn': 69.5, 'perc_fp': 8.0, 'perc_fn': 20.5, 'perc_tp': 2.0, 'sensitivity': 0.08888888888888889, 'tpr': 0.08888888888888889, 'recall': 0.08888888888888889, 'fpr': 0.1032258064516129, 'precision': 0.2, 'ppv': 0.2, 'specificity': 0.896774193548387, 'tnr': 0.896774193548387, 'f1_score': 0.12307692307692307, 'auc': 0.4928315412186379, 'kappa': -0.017857142857142794, 'accuracy': 0.715} \n",
      "\n",
      "{'model': 'xgboost', 'fold': 3, 'tn': 139, 'fp': 15, 'fn': 39, 'tp': 6, 'perc_tn': 69.84924623115577, 'perc_fp': 7.537688442211055, 'perc_fn': 19.597989949748744, 'perc_tp': 3.015075376884422, 'sensitivity': 0.13333333333333333, 'tpr': 0.13333333333333333, 'recall': 0.13333333333333333, 'fpr': 0.09740259740259741, 'precision': 0.2857142857142857, 'ppv': 0.2857142857142857, 'specificity': 0.9025974025974026, 'tnr': 0.9025974025974026, 'f1_score': 0.18181818181818182, 'auc': 0.517965367965368, 'kappa': 0.04429028815368208, 'accuracy': 0.7286432160804021} \n",
      "\n",
      "{'model': 'xgboost', 'fold': 4, 'tn': 145, 'fp': 9, 'fn': 42, 'tp': 3, 'perc_tn': 72.8643216080402, 'perc_fp': 4.522613065326634, 'perc_fn': 21.105527638190953, 'perc_tp': 1.507537688442211, 'sensitivity': 0.06666666666666667, 'tpr': 0.06666666666666667, 'recall': 0.06666666666666667, 'fpr': 0.05844155844155844, 'precision': 0.25, 'ppv': 0.25, 'specificity': 0.9415584415584416, 'tnr': 0.9415584415584416, 'f1_score': 0.10526315789473685, 'auc': 0.5041125541125541, 'kappa': 0.011107863197895251, 'accuracy': 0.7437185929648241} \n",
      "\n",
      "{'model': 'logistic_regression', 'fold': 0, 'tn': 154, 'fp': 1, 'fn': 45, 'tp': 0, 'perc_tn': 77.0, 'perc_fp': 0.5, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0064516129032258064, 'precision': 0.0, 'ppv': 0.0, 'specificity': 0.9935483870967742, 'tnr': 0.9935483870967742, 'f1_score': nan, 'auc': 0.4967741935483871, 'kappa': -0.009879253567508295, 'accuracy': 0.77} \n",
      "\n",
      "{'model': 'logistic_regression', 'fold': 1, 'tn': 154, 'fp': 1, 'fn': 45, 'tp': 0, 'perc_tn': 77.0, 'perc_fp': 0.5, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0064516129032258064, 'precision': 0.0, 'ppv': 0.0, 'specificity': 0.9935483870967742, 'tnr': 0.9935483870967742, 'f1_score': nan, 'auc': 0.4967741935483871, 'kappa': -0.009879253567508295, 'accuracy': 0.77} \n",
      "\n",
      "{'model': 'logistic_regression', 'fold': 2, 'tn': 155, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.5, 'perc_fp': 0.0, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.775} \n",
      "\n",
      "{'model': 'logistic_regression', 'fold': 3, 'tn': 154, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.38693467336684, 'perc_fp': 0.0, 'perc_fn': 22.613065326633166, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.7738693467336684} \n",
      "\n",
      "{'model': 'logistic_regression', 'fold': 4, 'tn': 152, 'fp': 2, 'fn': 45, 'tp': 0, 'perc_tn': 76.38190954773869, 'perc_fp': 1.0050251256281406, 'perc_fn': 22.613065326633166, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.012987012987012988, 'precision': 0.0, 'ppv': 0.0, 'specificity': 0.987012987012987, 'tnr': 0.987012987012987, 'f1_score': nan, 'auc': 0.4935064935064935, 'kappa': -0.01962280606126665, 'accuracy': 0.7638190954773869} \n",
      "\n",
      "{'model': 'random_forest', 'fold': 0, 'tn': 149, 'fp': 6, 'fn': 45, 'tp': 0, 'perc_tn': 74.5, 'perc_fp': 3.0, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.03870967741935484, 'precision': 0.0, 'ppv': 0.0, 'specificity': 0.9612903225806452, 'tnr': 0.9612903225806452, 'f1_score': nan, 'auc': 0.4806451612903226, 'kappa': -0.05590062111801242, 'accuracy': 0.745} \n",
      "\n",
      "{'model': 'random_forest', 'fold': 1, 'tn': 152, 'fp': 3, 'fn': 44, 'tp': 1, 'perc_tn': 76.0, 'perc_fp': 1.5, 'perc_fn': 22.0, 'perc_tp': 0.5, 'sensitivity': 0.022222222222222223, 'tpr': 0.022222222222222223, 'recall': 0.022222222222222223, 'fpr': 0.01935483870967742, 'precision': 0.25, 'ppv': 0.25, 'specificity': 0.9806451612903225, 'tnr': 0.9806451612903225, 'f1_score': 0.04081632653061225, 'auc': 0.5014336917562724, 'kappa': 0.00423728813559332, 'accuracy': 0.765} \n",
      "\n",
      "{'model': 'random_forest', 'fold': 2, 'tn': 153, 'fp': 2, 'fn': 44, 'tp': 1, 'perc_tn': 76.5, 'perc_fp': 1.0, 'perc_fn': 22.0, 'perc_tp': 0.5, 'sensitivity': 0.022222222222222223, 'tpr': 0.022222222222222223, 'recall': 0.022222222222222223, 'fpr': 0.012903225806451613, 'precision': 0.3333333333333333, 'ppv': 0.3333333333333333, 'specificity': 0.9870967741935484, 'tnr': 0.9870967741935484, 'f1_score': 0.04166666666666667, 'auc': 0.5046594982078852, 'kappa': 0.01393354769560573, 'accuracy': 0.77} \n",
      "\n",
      "{'model': 'random_forest', 'fold': 3, 'tn': 152, 'fp': 2, 'fn': 45, 'tp': 0, 'perc_tn': 76.38190954773869, 'perc_fp': 1.0050251256281406, 'perc_fn': 22.613065326633166, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.012987012987012988, 'precision': 0.0, 'ppv': 0.0, 'specificity': 0.987012987012987, 'tnr': 0.987012987012987, 'f1_score': nan, 'auc': 0.4935064935064935, 'kappa': -0.01962280606126665, 'accuracy': 0.7638190954773869} \n",
      "\n",
      "{'model': 'random_forest', 'fold': 4, 'tn': 149, 'fp': 5, 'fn': 44, 'tp': 1, 'perc_tn': 74.87437185929649, 'perc_fp': 2.512562814070352, 'perc_fn': 22.110552763819097, 'perc_tp': 0.5025125628140703, 'sensitivity': 0.022222222222222223, 'tpr': 0.022222222222222223, 'recall': 0.022222222222222223, 'fpr': 0.032467532467532464, 'precision': 0.16666666666666666, 'ppv': 0.16666666666666666, 'specificity': 0.9675324675324676, 'tnr': 0.9675324675324676, 'f1_score': 0.0392156862745098, 'auc': 0.49487734487734486, 'kappa': -0.014777812467478224, 'accuracy': 0.7537688442211056} \n",
      "\n",
      "{'model': 'gradient_boosting', 'fold': 0, 'tn': 141, 'fp': 14, 'fn': 43, 'tp': 2, 'perc_tn': 70.5, 'perc_fp': 7.000000000000001, 'perc_fn': 21.5, 'perc_tp': 1.0, 'sensitivity': 0.044444444444444446, 'tpr': 0.044444444444444446, 'recall': 0.044444444444444446, 'fpr': 0.09032258064516129, 'precision': 0.125, 'ppv': 0.125, 'specificity': 0.9096774193548387, 'tnr': 0.9096774193548387, 'f1_score': 0.06557377049180328, 'auc': 0.4770609318996416, 'kappa': -0.059479553903345694, 'accuracy': 0.715} \n",
      "\n",
      "{'model': 'gradient_boosting', 'fold': 1, 'tn': 151, 'fp': 4, 'fn': 42, 'tp': 3, 'perc_tn': 75.5, 'perc_fp': 2.0, 'perc_fn': 21.0, 'perc_tp': 1.5, 'sensitivity': 0.06666666666666667, 'tpr': 0.06666666666666667, 'recall': 0.06666666666666667, 'fpr': 0.025806451612903226, 'precision': 0.42857142857142855, 'ppv': 0.42857142857142855, 'specificity': 0.9741935483870968, 'tnr': 0.9741935483870968, 'f1_score': 0.11538461538461539, 'auc': 0.5204301075268817, 'kappa': 0.05834186284544518, 'accuracy': 0.77} \n",
      "\n",
      "{'model': 'gradient_boosting', 'fold': 2, 'tn': 148, 'fp': 7, 'fn': 42, 'tp': 3, 'perc_tn': 74.0, 'perc_fp': 3.5000000000000004, 'perc_fn': 21.0, 'perc_tp': 1.5, 'sensitivity': 0.06666666666666667, 'tpr': 0.06666666666666667, 'recall': 0.06666666666666667, 'fpr': 0.04516129032258064, 'precision': 0.3, 'ppv': 0.3, 'specificity': 0.9548387096774194, 'tnr': 0.9548387096774194, 'f1_score': 0.1090909090909091, 'auc': 0.510752688172043, 'kappa': 0.02970297029702973, 'accuracy': 0.755} \n",
      "\n",
      "{'model': 'gradient_boosting', 'fold': 3, 'tn': 144, 'fp': 10, 'fn': 44, 'tp': 1, 'perc_tn': 72.36180904522614, 'perc_fp': 5.025125628140704, 'perc_fn': 22.110552763819097, 'perc_tp': 0.5025125628140703, 'sensitivity': 0.022222222222222223, 'tpr': 0.022222222222222223, 'recall': 0.022222222222222223, 'fpr': 0.06493506493506493, 'precision': 0.09090909090909091, 'ppv': 0.09090909090909091, 'specificity': 0.935064935064935, 'tnr': 0.935064935064935, 'f1_score': 0.03571428571428571, 'auc': 0.4786435786435786, 'kappa': -0.05830214693716762, 'accuracy': 0.7286432160804021} \n",
      "\n",
      "{'model': 'gradient_boosting', 'fold': 4, 'tn': 145, 'fp': 9, 'fn': 44, 'tp': 1, 'perc_tn': 72.8643216080402, 'perc_fp': 4.522613065326634, 'perc_fn': 22.110552763819097, 'perc_tp': 0.5025125628140703, 'sensitivity': 0.022222222222222223, 'tpr': 0.022222222222222223, 'recall': 0.022222222222222223, 'fpr': 0.05844155844155844, 'precision': 0.1, 'ppv': 0.1, 'specificity': 0.9415584415584416, 'tnr': 0.9415584415584416, 'f1_score': 0.03636363636363636, 'auc': 0.48189033189033187, 'kappa': -0.04997511199601812, 'accuracy': 0.7336683417085427} \n",
      "\n",
      "{'model': 'svm', 'fold': 0, 'tn': 155, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.5, 'perc_fp': 0.0, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.775} \n",
      "\n",
      "{'model': 'svm', 'fold': 1, 'tn': 155, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.5, 'perc_fp': 0.0, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.775} \n",
      "\n",
      "{'model': 'svm', 'fold': 2, 'tn': 155, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.5, 'perc_fp': 0.0, 'perc_fn': 22.5, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.775} \n",
      "\n",
      "{'model': 'svm', 'fold': 3, 'tn': 154, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.38693467336684, 'perc_fp': 0.0, 'perc_fn': 22.613065326633166, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.7738693467336684} \n",
      "\n",
      "{'model': 'svm', 'fold': 4, 'tn': 154, 'fp': 0, 'fn': 45, 'tp': 0, 'perc_tn': 77.38693467336684, 'perc_fp': 0.0, 'perc_fn': 22.613065326633166, 'perc_tp': 0.0, 'sensitivity': 0.0, 'tpr': 0.0, 'recall': 0.0, 'fpr': 0.0, 'precision': nan, 'ppv': nan, 'specificity': 1.0, 'tnr': 1.0, 'f1_score': nan, 'auc': 0.5, 'kappa': 0.0, 'accuracy': 0.7738693467336684} \n",
      "\n",
      "{'model': 'knn', 'fold': 0, 'tn': 145, 'fp': 10, 'fn': 37, 'tp': 8, 'perc_tn': 72.5, 'perc_fp': 5.0, 'perc_fn': 18.5, 'perc_tp': 4.0, 'sensitivity': 0.17777777777777778, 'tpr': 0.17777777777777778, 'recall': 0.17777777777777778, 'fpr': 0.06451612903225806, 'precision': 0.4444444444444444, 'ppv': 0.4444444444444444, 'specificity': 0.9354838709677419, 'tnr': 0.9354838709677419, 'f1_score': 0.25396825396825395, 'auc': 0.5566308243727599, 'kappa': 0.14389799635701284, 'accuracy': 0.765} \n",
      "\n",
      "{'model': 'knn', 'fold': 1, 'tn': 130, 'fp': 25, 'fn': 38, 'tp': 7, 'perc_tn': 65.0, 'perc_fp': 12.5, 'perc_fn': 19.0, 'perc_tp': 3.5000000000000004, 'sensitivity': 0.15555555555555556, 'tpr': 0.15555555555555556, 'recall': 0.15555555555555556, 'fpr': 0.16129032258064516, 'precision': 0.21875, 'ppv': 0.21875, 'specificity': 0.8387096774193549, 'tnr': 0.8387096774193549, 'f1_score': 0.18181818181818185, 'auc': 0.49713261648745516, 'kappa': -0.006389776357827559, 'accuracy': 0.685} \n",
      "\n",
      "{'model': 'knn', 'fold': 2, 'tn': 138, 'fp': 17, 'fn': 38, 'tp': 7, 'perc_tn': 69.0, 'perc_fp': 8.5, 'perc_fn': 19.0, 'perc_tp': 3.5000000000000004, 'sensitivity': 0.15555555555555556, 'tpr': 0.15555555555555556, 'recall': 0.15555555555555556, 'fpr': 0.10967741935483871, 'precision': 0.2916666666666667, 'ppv': 0.2916666666666667, 'specificity': 0.8903225806451613, 'tnr': 0.8903225806451613, 'f1_score': 0.2028985507246377, 'auc': 0.5229390681003584, 'kappa': 0.054982817869415834, 'accuracy': 0.725} \n",
      "\n",
      "{'model': 'knn', 'fold': 3, 'tn': 132, 'fp': 22, 'fn': 33, 'tp': 12, 'perc_tn': 66.33165829145729, 'perc_fp': 11.055276381909549, 'perc_fn': 16.582914572864322, 'perc_tp': 6.030150753768844, 'sensitivity': 0.26666666666666666, 'tpr': 0.26666666666666666, 'recall': 0.26666666666666666, 'fpr': 0.14285714285714285, 'precision': 0.35294117647058826, 'ppv': 0.35294117647058826, 'specificity': 0.8571428571428571, 'tnr': 0.8571428571428571, 'f1_score': 0.3037974683544304, 'auc': 0.561904761904762, 'kappa': 0.13553431798436144, 'accuracy': 0.7236180904522613} \n",
      "\n",
      "{'model': 'knn', 'fold': 4, 'tn': 127, 'fp': 27, 'fn': 40, 'tp': 5, 'perc_tn': 63.81909547738693, 'perc_fp': 13.5678391959799, 'perc_fn': 20.100502512562816, 'perc_tp': 2.512562814070352, 'sensitivity': 0.1111111111111111, 'tpr': 0.1111111111111111, 'recall': 0.1111111111111111, 'fpr': 0.17532467532467533, 'precision': 0.15625, 'ppv': 0.15625, 'specificity': 0.8246753246753247, 'tnr': 0.8246753246753247, 'f1_score': 0.12987012987012989, 'auc': 0.46789321789321786, 'kappa': -0.07152615928634565, 'accuracy': 0.6633165829145728} \n",
      "\n",
      "{'model': 'decision_tree', 'fold': 0, 'tn': 116, 'fp': 39, 'fn': 37, 'tp': 8, 'perc_tn': 57.99999999999999, 'perc_fp': 19.5, 'perc_fn': 18.5, 'perc_tp': 4.0, 'sensitivity': 0.17777777777777778, 'tpr': 0.17777777777777778, 'recall': 0.17777777777777778, 'fpr': 0.25161290322580643, 'precision': 0.1702127659574468, 'ppv': 0.1702127659574468, 'specificity': 0.7483870967741936, 'tnr': 0.7483870967741936, 'f1_score': 0.1739130434782609, 'auc': 0.4630824372759857, 'kappa': -0.07268877911079752, 'accuracy': 0.62} \n",
      "\n",
      "{'model': 'decision_tree', 'fold': 1, 'tn': 127, 'fp': 28, 'fn': 36, 'tp': 9, 'perc_tn': 63.5, 'perc_fp': 14.000000000000002, 'perc_fn': 18.0, 'perc_tp': 4.5, 'sensitivity': 0.2, 'tpr': 0.2, 'recall': 0.2, 'fpr': 0.18064516129032257, 'precision': 0.24324324324324326, 'ppv': 0.24324324324324326, 'specificity': 0.8193548387096774, 'tnr': 0.8193548387096774, 'f1_score': 0.21951219512195122, 'auc': 0.5096774193548387, 'kappa': 0.020657995409334218, 'accuracy': 0.68} \n",
      "\n",
      "{'model': 'decision_tree', 'fold': 2, 'tn': 119, 'fp': 36, 'fn': 37, 'tp': 8, 'perc_tn': 59.5, 'perc_fp': 18.0, 'perc_fn': 18.5, 'perc_tp': 4.0, 'sensitivity': 0.17777777777777778, 'tpr': 0.17777777777777778, 'recall': 0.17777777777777778, 'fpr': 0.23225806451612904, 'precision': 0.18181818181818182, 'ppv': 0.18181818181818182, 'specificity': 0.7677419354838709, 'tnr': 0.7677419354838709, 'f1_score': 0.1797752808988764, 'auc': 0.47275985663082437, 'kappa': -0.054913294797687806, 'accuracy': 0.635} \n",
      "\n",
      "{'model': 'decision_tree', 'fold': 3, 'tn': 123, 'fp': 31, 'fn': 29, 'tp': 16, 'perc_tn': 61.80904522613066, 'perc_fp': 15.577889447236181, 'perc_fn': 14.572864321608039, 'perc_tp': 8.040201005025125, 'sensitivity': 0.35555555555555557, 'tpr': 0.35555555555555557, 'recall': 0.35555555555555557, 'fpr': 0.2012987012987013, 'precision': 0.3404255319148936, 'ppv': 0.3404255319148936, 'specificity': 0.7987012987012987, 'tnr': 0.7987012987012987, 'f1_score': 0.3478260869565218, 'auc': 0.5771284271284272, 'kappa': 0.1518681630913482, 'accuracy': 0.6984924623115578} \n",
      "\n",
      "{'model': 'decision_tree', 'fold': 4, 'tn': 111, 'fp': 43, 'fn': 41, 'tp': 4, 'perc_tn': 55.778894472361806, 'perc_fp': 21.608040201005025, 'perc_fn': 20.603015075376884, 'perc_tp': 2.0100502512562812, 'sensitivity': 0.08888888888888889, 'tpr': 0.08888888888888889, 'recall': 0.08888888888888889, 'fpr': 0.2792207792207792, 'precision': 0.0851063829787234, 'ppv': 0.0851063829787234, 'specificity': 0.7207792207792207, 'tnr': 0.7207792207792207, 'f1_score': 0.08695652173913045, 'auc': 0.4048340548340548, 'kappa': -0.18738457167211253, 'accuracy': 0.5778894472361809} \n",
      "\n",
      "{'model': 'naive_bayes', 'fold': 0, 'tn': 35, 'fp': 120, 'fn': 7, 'tp': 38, 'perc_tn': 17.5, 'perc_fp': 60.0, 'perc_fn': 3.5000000000000004, 'perc_tp': 19.0, 'sensitivity': 0.8444444444444444, 'tpr': 0.8444444444444444, 'recall': 0.8444444444444444, 'fpr': 0.7741935483870968, 'precision': 0.24050632911392406, 'ppv': 0.24050632911392406, 'specificity': 0.22580645161290322, 'tnr': 0.22580645161290322, 'f1_score': 0.37438423645320196, 'auc': 0.5351254480286738, 'kappa': 0.0371493555724034, 'accuracy': 0.365} \n",
      "\n",
      "{'model': 'naive_bayes', 'fold': 1, 'tn': 51, 'fp': 104, 'fn': 20, 'tp': 25, 'perc_tn': 25.5, 'perc_fp': 52.0, 'perc_fn': 10.0, 'perc_tp': 12.5, 'sensitivity': 0.5555555555555556, 'tpr': 0.5555555555555556, 'recall': 0.5555555555555556, 'fpr': 0.6709677419354839, 'precision': 0.1937984496124031, 'ppv': 0.1937984496124031, 'specificity': 0.32903225806451614, 'tnr': 0.32903225806451614, 'f1_score': 0.28735632183908044, 'auc': 0.4422939068100358, 'kappa': -0.06942647692971127, 'accuracy': 0.38} \n",
      "\n",
      "{'model': 'naive_bayes', 'fold': 2, 'tn': 46, 'fp': 109, 'fn': 13, 'tp': 32, 'perc_tn': 23.0, 'perc_fp': 54.50000000000001, 'perc_fn': 6.5, 'perc_tp': 16.0, 'sensitivity': 0.7111111111111111, 'tpr': 0.7111111111111111, 'recall': 0.7111111111111111, 'fpr': 0.7032258064516129, 'precision': 0.22695035460992907, 'ppv': 0.22695035460992907, 'specificity': 0.2967741935483871, 'tnr': 0.2967741935483871, 'f1_score': 0.34408602150537637, 'auc': 0.5039426523297492, 'kappa': 0.004487964096287267, 'accuracy': 0.39} \n",
      "\n",
      "{'model': 'naive_bayes', 'fold': 3, 'tn': 61, 'fp': 93, 'fn': 11, 'tp': 34, 'perc_tn': 30.65326633165829, 'perc_fp': 46.733668341708544, 'perc_fn': 5.527638190954774, 'perc_tp': 17.08542713567839, 'sensitivity': 0.7555555555555555, 'tpr': 0.7555555555555555, 'recall': 0.7555555555555555, 'fpr': 0.6038961038961039, 'precision': 0.2677165354330709, 'ppv': 0.2677165354330709, 'specificity': 0.3961038961038961, 'tnr': 0.3961038961038961, 'f1_score': 0.39534883720930236, 'auc': 0.5758297258297258, 'kappa': 0.09220107026932178, 'accuracy': 0.47738693467336685} \n",
      "\n",
      "{'model': 'naive_bayes', 'fold': 4, 'tn': 55, 'fp': 99, 'fn': 14, 'tp': 31, 'perc_tn': 27.63819095477387, 'perc_fp': 49.74874371859296, 'perc_fn': 7.035175879396985, 'perc_tp': 15.577889447236181, 'sensitivity': 0.6888888888888889, 'tpr': 0.6888888888888889, 'recall': 0.6888888888888889, 'fpr': 0.6428571428571429, 'precision': 0.23846153846153847, 'ppv': 0.23846153846153847, 'specificity': 0.35714285714285715, 'tnr': 0.35714285714285715, 'f1_score': 0.3542857142857143, 'auc': 0.523015873015873, 'kappa': 0.02758918918918929, 'accuracy': 0.4321608040201005} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprime os resultados\n",
    "for i, resultado in enumerate(resultados):\n",
    "    print(resultados[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febcccb0-33ed-47c3-a811-36d2b2a346d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>perc_tn</th>\n",
       "      <th>perc_fp</th>\n",
       "      <th>perc_fn</th>\n",
       "      <th>perc_tp</th>\n",
       "      <th>...</th>\n",
       "      <th>recall</th>\n",
       "      <th>fpr</th>\n",
       "      <th>precision</th>\n",
       "      <th>ppv</th>\n",
       "      <th>specificity</th>\n",
       "      <th>tnr</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.122581</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.877419</td>\n",
       "      <td>0.877419</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.472043</td>\n",
       "      <td>-0.068301</td>\n",
       "      <td>0.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.536201</td>\n",
       "      <td>0.098923</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.492832</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>69.849246</td>\n",
       "      <td>7.537688</td>\n",
       "      <td>19.597990</td>\n",
       "      <td>3.015075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.097403</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.902597</td>\n",
       "      <td>0.902597</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.044290</td>\n",
       "      <td>0.728643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>72.864322</td>\n",
       "      <td>4.522613</td>\n",
       "      <td>21.105528</td>\n",
       "      <td>1.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.504113</td>\n",
       "      <td>0.011108</td>\n",
       "      <td>0.743719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>-0.009879</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>-0.009879</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>76.381910</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>0.763819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.480645</td>\n",
       "      <td>-0.055901</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.504659</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>76.381910</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>0.763819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>74.874372</td>\n",
       "      <td>2.512563</td>\n",
       "      <td>22.110553</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.494877</td>\n",
       "      <td>-0.014778</td>\n",
       "      <td>0.753769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.477061</td>\n",
       "      <td>-0.059480</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.520430</td>\n",
       "      <td>0.058342</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.510753</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>72.361809</td>\n",
       "      <td>5.025126</td>\n",
       "      <td>22.110553</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.478644</td>\n",
       "      <td>-0.058302</td>\n",
       "      <td>0.728643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>72.864322</td>\n",
       "      <td>4.522613</td>\n",
       "      <td>22.110553</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.481890</td>\n",
       "      <td>-0.049975</td>\n",
       "      <td>0.733668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>svm</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knn</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.556631</td>\n",
       "      <td>0.143898</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.497133</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.109677</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.522939</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>66.331658</td>\n",
       "      <td>11.055276</td>\n",
       "      <td>16.582915</td>\n",
       "      <td>6.030151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.135534</td>\n",
       "      <td>0.723618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>63.819095</td>\n",
       "      <td>13.567839</td>\n",
       "      <td>20.100503</td>\n",
       "      <td>2.512563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.467893</td>\n",
       "      <td>-0.071526</td>\n",
       "      <td>0.663317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.463082</td>\n",
       "      <td>-0.072689</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.472760</td>\n",
       "      <td>-0.054913</td>\n",
       "      <td>0.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>61.809045</td>\n",
       "      <td>15.577889</td>\n",
       "      <td>14.572864</td>\n",
       "      <td>8.040201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.577128</td>\n",
       "      <td>0.151868</td>\n",
       "      <td>0.698492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>55.778894</td>\n",
       "      <td>21.608040</td>\n",
       "      <td>20.603015</td>\n",
       "      <td>2.010050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.404834</td>\n",
       "      <td>-0.187385</td>\n",
       "      <td>0.577889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.374384</td>\n",
       "      <td>0.535125</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>0.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>104</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.442294</td>\n",
       "      <td>-0.069426</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>109</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.226950</td>\n",
       "      <td>0.226950</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.503943</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>93</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>30.653266</td>\n",
       "      <td>46.733668</td>\n",
       "      <td>5.527638</td>\n",
       "      <td>17.085427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.603896</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.396104</td>\n",
       "      <td>0.396104</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.575830</td>\n",
       "      <td>0.092201</td>\n",
       "      <td>0.477387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>27.638191</td>\n",
       "      <td>49.748744</td>\n",
       "      <td>7.035176</td>\n",
       "      <td>15.577889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0.523016</td>\n",
       "      <td>0.027589</td>\n",
       "      <td>0.432161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  fold   tn   fp  fn  tp    perc_tn    perc_fp  \\\n",
       "0               xgboost     0  136   19  42   3  68.000000   9.500000   \n",
       "1               xgboost     1  149    6  40   5  74.500000   3.000000   \n",
       "2               xgboost     2  139   16  41   4  69.500000   8.000000   \n",
       "3               xgboost     3  139   15  39   6  69.849246   7.537688   \n",
       "4               xgboost     4  145    9  42   3  72.864322   4.522613   \n",
       "5   logistic_regression     0  154    1  45   0  77.000000   0.500000   \n",
       "6   logistic_regression     1  154    1  45   0  77.000000   0.500000   \n",
       "7   logistic_regression     2  155    0  45   0  77.500000   0.000000   \n",
       "8   logistic_regression     3  154    0  45   0  77.386935   0.000000   \n",
       "9   logistic_regression     4  152    2  45   0  76.381910   1.005025   \n",
       "10        random_forest     0  149    6  45   0  74.500000   3.000000   \n",
       "11        random_forest     1  152    3  44   1  76.000000   1.500000   \n",
       "12        random_forest     2  153    2  44   1  76.500000   1.000000   \n",
       "13        random_forest     3  152    2  45   0  76.381910   1.005025   \n",
       "14        random_forest     4  149    5  44   1  74.874372   2.512563   \n",
       "15    gradient_boosting     0  141   14  43   2  70.500000   7.000000   \n",
       "16    gradient_boosting     1  151    4  42   3  75.500000   2.000000   \n",
       "17    gradient_boosting     2  148    7  42   3  74.000000   3.500000   \n",
       "18    gradient_boosting     3  144   10  44   1  72.361809   5.025126   \n",
       "19    gradient_boosting     4  145    9  44   1  72.864322   4.522613   \n",
       "20                  svm     0  155    0  45   0  77.500000   0.000000   \n",
       "21                  svm     1  155    0  45   0  77.500000   0.000000   \n",
       "22                  svm     2  155    0  45   0  77.500000   0.000000   \n",
       "23                  svm     3  154    0  45   0  77.386935   0.000000   \n",
       "24                  svm     4  154    0  45   0  77.386935   0.000000   \n",
       "25                  knn     0  145   10  37   8  72.500000   5.000000   \n",
       "26                  knn     1  130   25  38   7  65.000000  12.500000   \n",
       "27                  knn     2  138   17  38   7  69.000000   8.500000   \n",
       "28                  knn     3  132   22  33  12  66.331658  11.055276   \n",
       "29                  knn     4  127   27  40   5  63.819095  13.567839   \n",
       "30        decision_tree     0  116   39  37   8  58.000000  19.500000   \n",
       "31        decision_tree     1  127   28  36   9  63.500000  14.000000   \n",
       "32        decision_tree     2  119   36  37   8  59.500000  18.000000   \n",
       "33        decision_tree     3  123   31  29  16  61.809045  15.577889   \n",
       "34        decision_tree     4  111   43  41   4  55.778894  21.608040   \n",
       "35          naive_bayes     0   35  120   7  38  17.500000  60.000000   \n",
       "36          naive_bayes     1   51  104  20  25  25.500000  52.000000   \n",
       "37          naive_bayes     2   46  109  13  32  23.000000  54.500000   \n",
       "38          naive_bayes     3   61   93  11  34  30.653266  46.733668   \n",
       "39          naive_bayes     4   55   99  14  31  27.638191  49.748744   \n",
       "\n",
       "      perc_fn    perc_tp  ...    recall       fpr  precision       ppv  \\\n",
       "0   21.000000   1.500000  ...  0.066667  0.122581   0.136364  0.136364   \n",
       "1   20.000000   2.500000  ...  0.111111  0.038710   0.454545  0.454545   \n",
       "2   20.500000   2.000000  ...  0.088889  0.103226   0.200000  0.200000   \n",
       "3   19.597990   3.015075  ...  0.133333  0.097403   0.285714  0.285714   \n",
       "4   21.105528   1.507538  ...  0.066667  0.058442   0.250000  0.250000   \n",
       "5   22.500000   0.000000  ...  0.000000  0.006452   0.000000  0.000000   \n",
       "6   22.500000   0.000000  ...  0.000000  0.006452   0.000000  0.000000   \n",
       "7   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "8   22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "9   22.613065   0.000000  ...  0.000000  0.012987   0.000000  0.000000   \n",
       "10  22.500000   0.000000  ...  0.000000  0.038710   0.000000  0.000000   \n",
       "11  22.000000   0.500000  ...  0.022222  0.019355   0.250000  0.250000   \n",
       "12  22.000000   0.500000  ...  0.022222  0.012903   0.333333  0.333333   \n",
       "13  22.613065   0.000000  ...  0.000000  0.012987   0.000000  0.000000   \n",
       "14  22.110553   0.502513  ...  0.022222  0.032468   0.166667  0.166667   \n",
       "15  21.500000   1.000000  ...  0.044444  0.090323   0.125000  0.125000   \n",
       "16  21.000000   1.500000  ...  0.066667  0.025806   0.428571  0.428571   \n",
       "17  21.000000   1.500000  ...  0.066667  0.045161   0.300000  0.300000   \n",
       "18  22.110553   0.502513  ...  0.022222  0.064935   0.090909  0.090909   \n",
       "19  22.110553   0.502513  ...  0.022222  0.058442   0.100000  0.100000   \n",
       "20  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "21  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "22  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "23  22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "24  22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "25  18.500000   4.000000  ...  0.177778  0.064516   0.444444  0.444444   \n",
       "26  19.000000   3.500000  ...  0.155556  0.161290   0.218750  0.218750   \n",
       "27  19.000000   3.500000  ...  0.155556  0.109677   0.291667  0.291667   \n",
       "28  16.582915   6.030151  ...  0.266667  0.142857   0.352941  0.352941   \n",
       "29  20.100503   2.512563  ...  0.111111  0.175325   0.156250  0.156250   \n",
       "30  18.500000   4.000000  ...  0.177778  0.251613   0.170213  0.170213   \n",
       "31  18.000000   4.500000  ...  0.200000  0.180645   0.243243  0.243243   \n",
       "32  18.500000   4.000000  ...  0.177778  0.232258   0.181818  0.181818   \n",
       "33  14.572864   8.040201  ...  0.355556  0.201299   0.340426  0.340426   \n",
       "34  20.603015   2.010050  ...  0.088889  0.279221   0.085106  0.085106   \n",
       "35   3.500000  19.000000  ...  0.844444  0.774194   0.240506  0.240506   \n",
       "36  10.000000  12.500000  ...  0.555556  0.670968   0.193798  0.193798   \n",
       "37   6.500000  16.000000  ...  0.711111  0.703226   0.226950  0.226950   \n",
       "38   5.527638  17.085427  ...  0.755556  0.603896   0.267717  0.267717   \n",
       "39   7.035176  15.577889  ...  0.688889  0.642857   0.238462  0.238462   \n",
       "\n",
       "    specificity       tnr  f1_score       auc     kappa  accuracy  \n",
       "0      0.877419  0.877419  0.089552  0.472043 -0.068301  0.695000  \n",
       "1      0.961290  0.961290  0.178571  0.536201  0.098923  0.770000  \n",
       "2      0.896774  0.896774  0.123077  0.492832 -0.017857  0.715000  \n",
       "3      0.902597  0.902597  0.181818  0.517965  0.044290  0.728643  \n",
       "4      0.941558  0.941558  0.105263  0.504113  0.011108  0.743719  \n",
       "5      0.993548  0.993548       NaN  0.496774 -0.009879  0.770000  \n",
       "6      0.993548  0.993548       NaN  0.496774 -0.009879  0.770000  \n",
       "7      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "8      1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "9      0.987013  0.987013       NaN  0.493506 -0.019623  0.763819  \n",
       "10     0.961290  0.961290       NaN  0.480645 -0.055901  0.745000  \n",
       "11     0.980645  0.980645  0.040816  0.501434  0.004237  0.765000  \n",
       "12     0.987097  0.987097  0.041667  0.504659  0.013934  0.770000  \n",
       "13     0.987013  0.987013       NaN  0.493506 -0.019623  0.763819  \n",
       "14     0.967532  0.967532  0.039216  0.494877 -0.014778  0.753769  \n",
       "15     0.909677  0.909677  0.065574  0.477061 -0.059480  0.715000  \n",
       "16     0.974194  0.974194  0.115385  0.520430  0.058342  0.770000  \n",
       "17     0.954839  0.954839  0.109091  0.510753  0.029703  0.755000  \n",
       "18     0.935065  0.935065  0.035714  0.478644 -0.058302  0.728643  \n",
       "19     0.941558  0.941558  0.036364  0.481890 -0.049975  0.733668  \n",
       "20     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "21     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "22     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "23     1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "24     1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "25     0.935484  0.935484  0.253968  0.556631  0.143898  0.765000  \n",
       "26     0.838710  0.838710  0.181818  0.497133 -0.006390  0.685000  \n",
       "27     0.890323  0.890323  0.202899  0.522939  0.054983  0.725000  \n",
       "28     0.857143  0.857143  0.303797  0.561905  0.135534  0.723618  \n",
       "29     0.824675  0.824675  0.129870  0.467893 -0.071526  0.663317  \n",
       "30     0.748387  0.748387  0.173913  0.463082 -0.072689  0.620000  \n",
       "31     0.819355  0.819355  0.219512  0.509677  0.020658  0.680000  \n",
       "32     0.767742  0.767742  0.179775  0.472760 -0.054913  0.635000  \n",
       "33     0.798701  0.798701  0.347826  0.577128  0.151868  0.698492  \n",
       "34     0.720779  0.720779  0.086957  0.404834 -0.187385  0.577889  \n",
       "35     0.225806  0.225806  0.374384  0.535125  0.037149  0.365000  \n",
       "36     0.329032  0.329032  0.287356  0.442294 -0.069426  0.380000  \n",
       "37     0.296774  0.296774  0.344086  0.503943  0.004488  0.390000  \n",
       "38     0.396104  0.396104  0.395349  0.575830  0.092201  0.477387  \n",
       "39     0.357143  0.357143  0.354286  0.523016  0.027589  0.432161  \n",
       "\n",
       "[40 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20b8ad49-af54-45b9-bb39-669bc2cd80ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'iSQI', 'bSQI', 'fSQI', 'sSQI', 'kSQI', 'pSQI',\n",
       "       'zero_crossings_rate_sqi', 'mean_crossing_rate_sqi',\n",
       "       'find_max_lenght_repeated_true', 'flat_line_sqi', 'saturation_sqi',\n",
       "       'baseline_sqi', 'amplitude_sqi', 'rr_variability_sqi_mean',\n",
       "       'rr_variability_sqi_std', 'rr_variability_sqi_cv', 'power_sqi', 'bsqi',\n",
       "       'Labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbe98d80-9e42-4c2d-86b5-abe792e24c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['iSQI', 'fSQI', 'sSQI', 'kSQI', 'pSQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c664fe-d93c-4c11-a033-68379a93d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d1f4de9-a90e-423c-b65a-05e9928779b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iSQI</th>\n",
       "      <th>fSQI</th>\n",
       "      <th>sSQI</th>\n",
       "      <th>kSQI</th>\n",
       "      <th>pSQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.544039</td>\n",
       "      <td>-0.466121</td>\n",
       "      <td>19.392805</td>\n",
       "      <td>64.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>-2.174674</td>\n",
       "      <td>9.449453</td>\n",
       "      <td>49.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.278857</td>\n",
       "      <td>-0.668478</td>\n",
       "      <td>2.535006</td>\n",
       "      <td>45.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>4.419841</td>\n",
       "      <td>25.069053</td>\n",
       "      <td>47.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>4.682297</td>\n",
       "      <td>20.321459</td>\n",
       "      <td>78.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.486928</td>\n",
       "      <td>-1.396489</td>\n",
       "      <td>5.821627</td>\n",
       "      <td>56.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.599578</td>\n",
       "      <td>3.107946</td>\n",
       "      <td>14.621376</td>\n",
       "      <td>69.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.624298</td>\n",
       "      <td>3.345171</td>\n",
       "      <td>16.979691</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.665089</td>\n",
       "      <td>4.245285</td>\n",
       "      <td>19.330689</td>\n",
       "      <td>71.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iSQI      fSQI      sSQI       kSQI    pSQI\n",
       "0    0.00  0.000000  0.000000   0.000000  100.00\n",
       "1    0.20  0.544039 -0.466121  19.392805   64.56\n",
       "2    0.16  0.005520 -2.174674   9.449453   49.30\n",
       "3    0.30  0.278857 -0.668478   2.535006   45.08\n",
       "4    0.20  0.619605  4.419841  25.069053   47.04\n",
       "..    ...       ...       ...        ...     ...\n",
       "993  0.04  0.237600  4.682297  20.321459   78.22\n",
       "994  0.26  0.486928 -1.396489   5.821627   56.62\n",
       "995  0.24  0.599578  3.107946  14.621376   69.52\n",
       "996  0.24  0.624298  3.345171  16.979691   59.98\n",
       "997  0.26  0.665089  4.245285  19.330689   71.56\n",
       "\n",
       "[998 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b9de6f7-fde7-48b2-b46b-b042c8a5a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost (798, 5) (798,) (200, 5) (200,)\n",
      "xgboost (798, 5) (798,) (200, 5) (200,)\n",
      "xgboost (798, 5) (798,) (200, 5) (200,)\n",
      "xgboost (799, 5) (799,) (199, 5) (199,)\n",
      "xgboost (799, 5) (799,) (199, 5) (199,)\n",
      "logistic_regression (798, 5) (798,) (200, 5) (200,)\n",
      "logistic_regression (798, 5) (798,) (200, 5) (200,)\n",
      "logistic_regression (798, 5) (798,) (200, 5) (200,)\n",
      "logistic_regression (799, 5) (799,) (199, 5) (199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression (799, 5) (799,) (199, 5) (199,)\n",
      "random_forest (798, 5) (798,) (200, 5) (200,)\n",
      "random_forest (798, 5) (798,) (200, 5) (200,)\n",
      "random_forest (798, 5) (798,) (200, 5) (200,)\n",
      "random_forest (799, 5) (799,) (199, 5) (199,)\n",
      "random_forest (799, 5) (799,) (199, 5) (199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting (798, 5) (798,) (200, 5) (200,)\n",
      "gradient_boosting (798, 5) (798,) (200, 5) (200,)\n",
      "gradient_boosting (798, 5) (798,) (200, 5) (200,)\n",
      "gradient_boosting (799, 5) (799,) (199, 5) (199,)\n",
      "gradient_boosting (799, 5) (799,) (199, 5) (199,)\n",
      "svm (798, 5) (798,) (200, 5) (200,)\n",
      "svm (798, 5) (798,) (200, 5) (200,)\n",
      "svm (798, 5) (798,) (200, 5) (200,)\n",
      "svm (799, 5) (799,) (199, 5) (199,)\n",
      "svm (799, 5) (799,) (199, 5) (199,)\n",
      "knn (798, 5) (798,) (200, 5) (200,)\n",
      "knn (798, 5) (798,) (200, 5) (200,)\n",
      "knn (798, 5) (798,) (200, 5) (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn (799, 5) (799,) (199, 5) (199,)\n",
      "knn (799, 5) (799,) (199, 5) (199,)\n",
      "decision_tree (798, 5) (798,) (200, 5) (200,)\n",
      "decision_tree (798, 5) (798,) (200, 5) (200,)\n",
      "decision_tree (798, 5) (798,) (200, 5) (200,)\n",
      "decision_tree (799, 5) (799,) (199, 5) (199,)\n",
      "decision_tree (799, 5) (799,) (199, 5) (199,)\n",
      "naive_bayes (798, 5) (798,) (200, 5) (200,)\n",
      "naive_bayes (798, 5) (798,) (200, 5) (200,)\n",
      "naive_bayes (798, 5) (798,) (200, 5) (200,)\n",
      "naive_bayes (799, 5) (799,) (199, 5) (199,)\n",
      "naive_bayes (799, 5) (799,) (199, 5) (199,)\n"
     ]
    }
   ],
   "source": [
    "# Classificando K-FOLD\n",
    "resultados_1 = []\n",
    "\n",
    "for method in methods.keys():\n",
    "    m = methods[method]\n",
    "    \n",
    "    # Número de folds desejado\n",
    "    num_folds = 5\n",
    "    \n",
    "    # Inicialize o objeto StratifiedKFold\n",
    "    stratkf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Loop sobre os k-folds\n",
    "    for idx, (train_idx, test_idx) in enumerate(stratkf.split(X_1, y)):\n",
    "        \n",
    "        X_train, X_test = X_1.iloc[train_idx], X_1.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        print(method, X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        model = m.fit(X_train, y_train)\n",
    "        \n",
    "        # Faz predições no conjunto de teste\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Avalia o desempenho do modelo e armazena os resultados\n",
    "        results_fold = classification_metrics_binary(y_test, y_pred, method, idx)\n",
    "        resultados_1.append(results_fold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42df9ce0-13d8-4191-99c9-f365f197e321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>perc_tn</th>\n",
       "      <th>perc_fp</th>\n",
       "      <th>perc_fn</th>\n",
       "      <th>perc_tp</th>\n",
       "      <th>...</th>\n",
       "      <th>recall</th>\n",
       "      <th>fpr</th>\n",
       "      <th>precision</th>\n",
       "      <th>ppv</th>\n",
       "      <th>specificity</th>\n",
       "      <th>tnr</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.515054</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.515412</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.515054</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>65.829146</td>\n",
       "      <td>11.557789</td>\n",
       "      <td>18.090452</td>\n",
       "      <td>4.522613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.149351</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.850649</td>\n",
       "      <td>0.850649</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.525325</td>\n",
       "      <td>0.056417</td>\n",
       "      <td>0.703518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>64.824121</td>\n",
       "      <td>12.562814</td>\n",
       "      <td>20.100503</td>\n",
       "      <td>2.512563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.474387</td>\n",
       "      <td>-0.058078</td>\n",
       "      <td>0.673367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.520430</td>\n",
       "      <td>0.058342</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>76.381910</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>21.608040</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.515729</td>\n",
       "      <td>0.046427</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>73.869347</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>-0.064828</td>\n",
       "      <td>0.738693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.491756</td>\n",
       "      <td>-0.023541</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.515771</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>74.371859</td>\n",
       "      <td>3.015075</td>\n",
       "      <td>21.608040</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.502742</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.753769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>75.376884</td>\n",
       "      <td>2.010050</td>\n",
       "      <td>22.110553</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.498124</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>0.758794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>svm</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knn</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>0.151194</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.177215</td>\n",
       "      <td>0.490681</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.518280</td>\n",
       "      <td>0.045093</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>61.809045</td>\n",
       "      <td>15.577889</td>\n",
       "      <td>16.582915</td>\n",
       "      <td>6.030151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.532684</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.678392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>64.321608</td>\n",
       "      <td>13.065327</td>\n",
       "      <td>19.597990</td>\n",
       "      <td>3.015075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.168831</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.482251</td>\n",
       "      <td>-0.039540</td>\n",
       "      <td>0.673367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>0.066968</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.212903</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.471326</td>\n",
       "      <td>-0.059701</td>\n",
       "      <td>0.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.488172</td>\n",
       "      <td>-0.021611</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>57.788945</td>\n",
       "      <td>19.597990</td>\n",
       "      <td>16.080402</td>\n",
       "      <td>6.532663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>0.517821</td>\n",
       "      <td>0.033782</td>\n",
       "      <td>0.643216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>59.296482</td>\n",
       "      <td>18.090452</td>\n",
       "      <td>19.095477</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.460895</td>\n",
       "      <td>-0.079460</td>\n",
       "      <td>0.628141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.244275</td>\n",
       "      <td>0.451971</td>\n",
       "      <td>-0.072589</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.225610</td>\n",
       "      <td>0.225610</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.354067</td>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>132</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>11.055276</td>\n",
       "      <td>66.331658</td>\n",
       "      <td>4.020101</td>\n",
       "      <td>18.592965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.218935</td>\n",
       "      <td>0.218935</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.482540</td>\n",
       "      <td>-0.017680</td>\n",
       "      <td>0.296482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>15.577889</td>\n",
       "      <td>61.809045</td>\n",
       "      <td>2.512563</td>\n",
       "      <td>20.100503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.545094</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>0.356784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  fold   tn   fp  fn  tp    perc_tn    perc_fp  \\\n",
       "0               xgboost     0  139   16  39   6  69.500000   8.000000   \n",
       "1               xgboost     1  146    9  41   4  73.000000   4.500000   \n",
       "2               xgboost     2  139   16  39   6  69.500000   8.000000   \n",
       "3               xgboost     3  131   23  36   9  65.829146  11.557789   \n",
       "4               xgboost     4  129   25  40   5  64.824121  12.562814   \n",
       "5   logistic_regression     0  155    0  45   0  77.500000   0.000000   \n",
       "6   logistic_regression     1  155    0  45   0  77.500000   0.000000   \n",
       "7   logistic_regression     2  155    0  45   0  77.500000   0.000000   \n",
       "8   logistic_regression     3  154    0  45   0  77.386935   0.000000   \n",
       "9   logistic_regression     4  154    0  45   0  77.386935   0.000000   \n",
       "10        random_forest     0  151    4  44   1  75.500000   2.000000   \n",
       "11        random_forest     1  151    4  42   3  75.500000   2.000000   \n",
       "12        random_forest     2  152    3  44   1  76.000000   1.500000   \n",
       "13        random_forest     3  152    2  43   2  76.381910   1.005025   \n",
       "14        random_forest     4  147    7  45   0  73.869347   3.517588   \n",
       "15    gradient_boosting     0  149    6  44   1  74.500000   3.000000   \n",
       "16    gradient_boosting     1  151    4  44   1  75.500000   2.000000   \n",
       "17    gradient_boosting     2  153    2  43   2  76.500000   1.000000   \n",
       "18    gradient_boosting     3  148    6  43   2  74.371859   3.015075   \n",
       "19    gradient_boosting     4  150    4  44   1  75.376884   2.010050   \n",
       "20                  svm     0  155    0  45   0  77.500000   0.000000   \n",
       "21                  svm     1  155    0  45   0  77.500000   0.000000   \n",
       "22                  svm     2  155    0  45   0  77.500000   0.000000   \n",
       "23                  svm     3  154    0  45   0  77.386935   0.000000   \n",
       "24                  svm     4  154    0  45   0  77.386935   0.000000   \n",
       "25                  knn     0  143   12  36   9  71.500000   6.000000   \n",
       "26                  knn     1  128   27  38   7  64.000000  13.500000   \n",
       "27                  knn     2  140   15  39   6  70.000000   7.500000   \n",
       "28                  knn     3  123   31  33  12  61.809045  15.577889   \n",
       "29                  knn     4  128   26  39   6  64.321608  13.065327   \n",
       "30        decision_tree     0  127   28  34  11  63.500000  14.000000   \n",
       "31        decision_tree     1  122   33  38   7  61.000000  16.500000   \n",
       "32        decision_tree     2  110   45  33  12  55.000000  22.500000   \n",
       "33        decision_tree     3  115   39  32  13  57.788945  19.597990   \n",
       "34        decision_tree     4  118   36  38   7  59.296482  18.090452   \n",
       "35          naive_bayes     0   32  123   7  38  16.000000  61.500000   \n",
       "36          naive_bayes     1   85   70  29  16  42.500000  35.000000   \n",
       "37          naive_bayes     2   28  127   8  37  14.000000  63.500000   \n",
       "38          naive_bayes     3   22  132   8  37  11.055276  66.331658   \n",
       "39          naive_bayes     4   31  123   5  40  15.577889  61.809045   \n",
       "\n",
       "      perc_fn    perc_tp  ...    recall       fpr  precision       ppv  \\\n",
       "0   19.500000   3.000000  ...  0.133333  0.103226   0.272727  0.272727   \n",
       "1   20.500000   2.000000  ...  0.088889  0.058065   0.307692  0.307692   \n",
       "2   19.500000   3.000000  ...  0.133333  0.103226   0.272727  0.272727   \n",
       "3   18.090452   4.522613  ...  0.200000  0.149351   0.281250  0.281250   \n",
       "4   20.100503   2.512563  ...  0.111111  0.162338   0.166667  0.166667   \n",
       "5   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "6   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "7   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "8   22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "9   22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "10  22.000000   0.500000  ...  0.022222  0.025806   0.200000  0.200000   \n",
       "11  21.000000   1.500000  ...  0.066667  0.025806   0.428571  0.428571   \n",
       "12  22.000000   0.500000  ...  0.022222  0.019355   0.250000  0.250000   \n",
       "13  21.608040   1.005025  ...  0.044444  0.012987   0.500000  0.500000   \n",
       "14  22.613065   0.000000  ...  0.000000  0.045455   0.000000  0.000000   \n",
       "15  22.000000   0.500000  ...  0.022222  0.038710   0.142857  0.142857   \n",
       "16  22.000000   0.500000  ...  0.022222  0.025806   0.200000  0.200000   \n",
       "17  21.500000   1.000000  ...  0.044444  0.012903   0.500000  0.500000   \n",
       "18  21.608040   1.005025  ...  0.044444  0.038961   0.250000  0.250000   \n",
       "19  22.110553   0.502513  ...  0.022222  0.025974   0.200000  0.200000   \n",
       "20  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "21  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "22  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "23  22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "24  22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "25  18.000000   4.500000  ...  0.200000  0.077419   0.428571  0.428571   \n",
       "26  19.000000   3.500000  ...  0.155556  0.174194   0.205882  0.205882   \n",
       "27  19.500000   3.000000  ...  0.133333  0.096774   0.285714  0.285714   \n",
       "28  16.582915   6.030151  ...  0.266667  0.201299   0.279070  0.279070   \n",
       "29  19.597990   3.015075  ...  0.133333  0.168831   0.187500  0.187500   \n",
       "30  17.000000   5.500000  ...  0.244444  0.180645   0.282051  0.282051   \n",
       "31  19.000000   3.500000  ...  0.155556  0.212903   0.175000  0.175000   \n",
       "32  16.500000   6.000000  ...  0.266667  0.290323   0.210526  0.210526   \n",
       "33  16.080402   6.532663  ...  0.288889  0.253247   0.250000  0.250000   \n",
       "34  19.095477   3.517588  ...  0.155556  0.233766   0.162791  0.162791   \n",
       "35   3.500000  19.000000  ...  0.844444  0.793548   0.236025  0.236025   \n",
       "36  14.500000   8.000000  ...  0.355556  0.451613   0.186047  0.186047   \n",
       "37   4.000000  18.500000  ...  0.822222  0.819355   0.225610  0.225610   \n",
       "38   4.020101  18.592965  ...  0.822222  0.857143   0.218935  0.218935   \n",
       "39   2.512563  20.100503  ...  0.888889  0.798701   0.245399  0.245399   \n",
       "\n",
       "    specificity       tnr  f1_score       auc     kappa  accuracy  \n",
       "0      0.896774  0.896774  0.179104  0.515054  0.036778  0.725000  \n",
       "1      0.941935  0.941935  0.137931  0.515412  0.041227  0.750000  \n",
       "2      0.896774  0.896774  0.179104  0.515054  0.036778  0.725000  \n",
       "3      0.850649  0.850649  0.233766  0.525325  0.056417  0.703518  \n",
       "4      0.837662  0.837662  0.133333  0.474387 -0.058078  0.673367  \n",
       "5      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "6      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "7      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "8      1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "9      1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "10     0.974194  0.974194  0.040000  0.498208 -0.005236  0.760000  \n",
       "11     0.974194  0.974194  0.115385  0.520430  0.058342  0.770000  \n",
       "12     0.980645  0.980645  0.040816  0.501434  0.004237  0.765000  \n",
       "13     0.987013  0.987013  0.081633  0.515729  0.046427  0.773869  \n",
       "14     0.954545  0.954545       NaN  0.477273 -0.064828  0.738693  \n",
       "15     0.961290  0.961290  0.038462  0.491756 -0.023541  0.750000  \n",
       "16     0.974194  0.974194  0.040000  0.498208 -0.005236  0.760000  \n",
       "17     0.987097  0.987097  0.081633  0.515771  0.046610  0.775000  \n",
       "18     0.961039  0.961039  0.075472  0.502742  0.007734  0.753769  \n",
       "19     0.974026  0.974026  0.040000  0.498124 -0.005474  0.758794  \n",
       "20     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "21     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "22     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "23     1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "24     1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "25     0.922581  0.922581  0.272727  0.561290  0.151194  0.760000  \n",
       "26     0.825806  0.825806  0.177215  0.490681 -0.020408  0.675000  \n",
       "27     0.903226  0.903226  0.181818  0.518280  0.045093  0.730000  \n",
       "28     0.798701  0.798701  0.272727  0.532684  0.066413  0.678392  \n",
       "29     0.831169  0.831169  0.155844  0.482251 -0.039540  0.673367  \n",
       "30     0.819355  0.819355  0.261905  0.531900  0.066968  0.690000  \n",
       "31     0.787097  0.787097  0.164706  0.471326 -0.059701  0.645000  \n",
       "32     0.709677  0.709677  0.235294  0.488172 -0.021611  0.610000  \n",
       "33     0.746753  0.746753  0.268041  0.517821  0.033782  0.643216  \n",
       "34     0.766234  0.766234  0.159091  0.460895 -0.079460  0.628141  \n",
       "35     0.206452  0.206452  0.368932  0.525448  0.026582  0.350000  \n",
       "36     0.548387  0.548387  0.244275  0.451971 -0.072589  0.505000  \n",
       "37     0.180645  0.180645  0.354067  0.501434  0.001479  0.325000  \n",
       "38     0.142857  0.142857  0.345794  0.482540 -0.017680  0.296482  \n",
       "39     0.201299  0.201299  0.384615  0.545094  0.046778  0.356784  \n",
       "\n",
       "[40 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_1 = pd.DataFrame(resultados_1)\n",
    "df_resultados_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "382d99b7-7c5c-42ea-8567-81cc9bd263ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_2 = ['iSQI', 'sSQI', 'kSQI']\n",
    "X_2 = df[selected_features_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebd763d6-1ff3-46d4-9344-796ddf845d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iSQI</th>\n",
       "      <th>sSQI</th>\n",
       "      <th>kSQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.466121</td>\n",
       "      <td>19.392805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-2.174674</td>\n",
       "      <td>9.449453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.668478</td>\n",
       "      <td>2.535006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4.419841</td>\n",
       "      <td>25.069053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.04</td>\n",
       "      <td>4.682297</td>\n",
       "      <td>20.321459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.396489</td>\n",
       "      <td>5.821627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.24</td>\n",
       "      <td>3.107946</td>\n",
       "      <td>14.621376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.24</td>\n",
       "      <td>3.345171</td>\n",
       "      <td>16.979691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.26</td>\n",
       "      <td>4.245285</td>\n",
       "      <td>19.330689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iSQI      sSQI       kSQI\n",
       "0    0.00  0.000000   0.000000\n",
       "1    0.20 -0.466121  19.392805\n",
       "2    0.16 -2.174674   9.449453\n",
       "3    0.30 -0.668478   2.535006\n",
       "4    0.20  4.419841  25.069053\n",
       "..    ...       ...        ...\n",
       "993  0.04  4.682297  20.321459\n",
       "994  0.26 -1.396489   5.821627\n",
       "995  0.24  3.107946  14.621376\n",
       "996  0.24  3.345171  16.979691\n",
       "997  0.26  4.245285  19.330689\n",
       "\n",
       "[998 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a925773-ec50-4594-b72c-d8ffb2101102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost (798, 3) (798,) (200, 3) (200,)\n",
      "xgboost (798, 3) (798,) (200, 3) (200,)\n",
      "xgboost (798, 3) (798,) (200, 3) (200,)\n",
      "xgboost (799, 3) (799,) (199, 3) (199,)\n",
      "xgboost (799, 3) (799,) (199, 3) (199,)\n",
      "logistic_regression (798, 3) (798,) (200, 3) (200,)\n",
      "logistic_regression (798, 3) (798,) (200, 3) (200,)\n",
      "logistic_regression (798, 3) (798,) (200, 3) (200,)\n",
      "logistic_regression (799, 3) (799,) (199, 3) (199,)\n",
      "logistic_regression (799, 3) (799,) (199, 3) (199,)\n",
      "random_forest (798, 3) (798,) (200, 3) (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest (798, 3) (798,) (200, 3) (200,)\n",
      "random_forest (798, 3) (798,) (200, 3) (200,)\n",
      "random_forest (799, 3) (799,) (199, 3) (199,)\n",
      "random_forest (799, 3) (799,) (199, 3) (199,)\n",
      "gradient_boosting (798, 3) (798,) (200, 3) (200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2*precision*sensitivity/(sensitivity+precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting (798, 3) (798,) (200, 3) (200,)\n",
      "gradient_boosting (798, 3) (798,) (200, 3) (200,)\n",
      "gradient_boosting (799, 3) (799,) (199, 3) (199,)\n",
      "gradient_boosting (799, 3) (799,) (199, 3) (199,)\n",
      "svm (798, 3) (798,) (200, 3) (200,)\n",
      "svm (798, 3) (798,) (200, 3) (200,)\n",
      "svm (798, 3) (798,) (200, 3) (200,)\n",
      "svm (799, 3) (799,) (199, 3) (199,)\n",
      "svm (799, 3) (799,) (199, 3) (199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n",
      "C:\\Users\\estel\\AppData\\Local\\Temp\\ipykernel_10576\\2723367189.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn (798, 3) (798,) (200, 3) (200,)\n",
      "knn (798, 3) (798,) (200, 3) (200,)\n",
      "knn (798, 3) (798,) (200, 3) (200,)\n",
      "knn (799, 3) (799,) (199, 3) (199,)\n",
      "knn (799, 3) (799,) (199, 3) (199,)\n",
      "decision_tree (798, 3) (798,) (200, 3) (200,)\n",
      "decision_tree (798, 3) (798,) (200, 3) (200,)\n",
      "decision_tree (798, 3) (798,) (200, 3) (200,)\n",
      "decision_tree (799, 3) (799,) (199, 3) (199,)\n",
      "decision_tree (799, 3) (799,) (199, 3) (199,)\n",
      "naive_bayes (798, 3) (798,) (200, 3) (200,)\n",
      "naive_bayes (798, 3) (798,) (200, 3) (200,)\n",
      "naive_bayes (798, 3) (798,) (200, 3) (200,)\n",
      "naive_bayes (799, 3) (799,) (199, 3) (199,)\n",
      "naive_bayes (799, 3) (799,) (199, 3) (199,)\n"
     ]
    }
   ],
   "source": [
    "# Classificando K-FOLD\n",
    "resultados_2 = []\n",
    "\n",
    "for method in methods.keys():\n",
    "    m = methods[method]\n",
    "    \n",
    "    # Número de folds desejado\n",
    "    num_folds = 5\n",
    "    \n",
    "    # Inicialize o objeto StratifiedKFold\n",
    "    stratkf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Loop sobre os k-folds\n",
    "    for idx, (train_idx, test_idx) in enumerate(stratkf.split(X_2, y)):\n",
    "        \n",
    "        X_train, X_test = X_2.iloc[train_idx], X_2.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        print(method, X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        model = m.fit(X_train, y_train)\n",
    "        \n",
    "        # Faz predições no conjunto de teste\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Avalia o desempenho do modelo e armazena os resultados\n",
    "        results_fold = classification_metrics_binary(y_test, y_pred, method, idx)\n",
    "        resultados_2.append(results_fold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06c89c88-4dc4-4370-a6af-35a929bb3d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>perc_tn</th>\n",
       "      <th>perc_fp</th>\n",
       "      <th>perc_fn</th>\n",
       "      <th>perc_tp</th>\n",
       "      <th>...</th>\n",
       "      <th>recall</th>\n",
       "      <th>fpr</th>\n",
       "      <th>precision</th>\n",
       "      <th>ppv</th>\n",
       "      <th>specificity</th>\n",
       "      <th>tnr</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.523297</td>\n",
       "      <td>0.061033</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.480287</td>\n",
       "      <td>-0.051643</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.508244</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>66.834171</td>\n",
       "      <td>10.552764</td>\n",
       "      <td>18.592965</td>\n",
       "      <td>4.020101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.520707</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.708543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>69.346734</td>\n",
       "      <td>8.040201</td>\n",
       "      <td>21.105528</td>\n",
       "      <td>1.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.481385</td>\n",
       "      <td>-0.046798</td>\n",
       "      <td>0.708543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.486738</td>\n",
       "      <td>-0.035475</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.496416</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>2</td>\n",
       "      <td>137</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.508602</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>73.869347</td>\n",
       "      <td>3.517588</td>\n",
       "      <td>20.603015</td>\n",
       "      <td>2.010050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.521717</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>0.758794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>72.864322</td>\n",
       "      <td>4.522613</td>\n",
       "      <td>21.608040</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.493001</td>\n",
       "      <td>-0.019106</td>\n",
       "      <td>0.738693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>-0.028939</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.515771</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.521864</td>\n",
       "      <td>0.059745</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>74.371859</td>\n",
       "      <td>3.015075</td>\n",
       "      <td>21.608040</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.502742</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.753769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>72.864322</td>\n",
       "      <td>4.522613</td>\n",
       "      <td>22.110553</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.481890</td>\n",
       "      <td>-0.049975</td>\n",
       "      <td>0.733668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>svm</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>svm</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>svm</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>svm</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>77.386935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.613065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knn</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.470609</td>\n",
       "      <td>-0.074681</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.524014</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.534409</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>66.331658</td>\n",
       "      <td>11.055276</td>\n",
       "      <td>18.090452</td>\n",
       "      <td>4.522613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>0.708543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>63.819095</td>\n",
       "      <td>13.567839</td>\n",
       "      <td>18.592965</td>\n",
       "      <td>4.020101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.501227</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.678392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.530466</td>\n",
       "      <td>0.066148</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.453763</td>\n",
       "      <td>-0.095485</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.528315</td>\n",
       "      <td>0.054899</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>63.316583</td>\n",
       "      <td>14.070352</td>\n",
       "      <td>16.080402</td>\n",
       "      <td>6.532663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.553535</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>0.698492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>63.316583</td>\n",
       "      <td>14.070352</td>\n",
       "      <td>16.582915</td>\n",
       "      <td>6.030151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.542424</td>\n",
       "      <td>0.088321</td>\n",
       "      <td>0.693467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.432258</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>-0.024523</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.220859</td>\n",
       "      <td>0.220859</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>-0.010026</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>10.050251</td>\n",
       "      <td>67.336683</td>\n",
       "      <td>4.020101</td>\n",
       "      <td>18.592965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.216374</td>\n",
       "      <td>0.216374</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.342593</td>\n",
       "      <td>0.476046</td>\n",
       "      <td>-0.024063</td>\n",
       "      <td>0.286432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>8.040201</td>\n",
       "      <td>69.346734</td>\n",
       "      <td>1.005025</td>\n",
       "      <td>21.608040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.028727</td>\n",
       "      <td>0.296482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  fold   tn   fp  fn  tp    perc_tn    perc_fp  \\\n",
       "0               xgboost     0  145   10  40   5  72.500000   5.000000   \n",
       "1               xgboost     1  142   13  43   2  71.000000   6.500000   \n",
       "2               xgboost     2  130   25  37   8  65.000000  12.500000   \n",
       "3               xgboost     3  133   21  37   8  66.834171  10.552764   \n",
       "4               xgboost     4  138   16  42   3  69.346734   8.040201   \n",
       "5   logistic_regression     0  155    0  45   0  77.500000   0.000000   \n",
       "6   logistic_regression     1  155    0  45   0  77.500000   0.000000   \n",
       "7   logistic_regression     2  155    0  45   0  77.500000   0.000000   \n",
       "8   logistic_regression     3  154    0  45   0  77.386935   0.000000   \n",
       "9   logistic_regression     4  154    0  45   0  77.386935   0.000000   \n",
       "10        random_forest     0  144   11  43   2  72.000000   5.500000   \n",
       "11        random_forest     1  147    8  43   2  73.500000   4.000000   \n",
       "12        random_forest     2  137   18  39   6  68.500000   9.000000   \n",
       "13        random_forest     3  147    7  41   4  73.869347   3.517588   \n",
       "14        random_forest     4  145    9  43   2  72.864322   4.522613   \n",
       "15    gradient_boosting     0  152    3  45   0  76.000000   1.500000   \n",
       "16    gradient_boosting     1  153    2  43   2  76.500000   1.000000   \n",
       "17    gradient_boosting     2  148    7  41   4  74.000000   3.500000   \n",
       "18    gradient_boosting     3  148    6  43   2  74.371859   3.015075   \n",
       "19    gradient_boosting     4  145    9  44   1  72.864322   4.522613   \n",
       "20                  svm     0  155    0  45   0  77.500000   0.000000   \n",
       "21                  svm     1  155    0  45   0  77.500000   0.000000   \n",
       "22                  svm     2  155    0  45   0  77.500000   0.000000   \n",
       "23                  svm     3  154    0  45   0  77.386935   0.000000   \n",
       "24                  svm     4  154    0  45   0  77.386935   0.000000   \n",
       "25                  knn     0  139   16  43   2  69.500000   8.000000   \n",
       "26                  knn     1  128   27  35  10  64.000000  13.500000   \n",
       "27                  knn     2  145   10  39   6  72.500000   5.000000   \n",
       "28                  knn     3  132   22  36   9  66.331658  11.055276   \n",
       "29                  knn     4  127   27  37   8  63.819095  13.567839   \n",
       "30        decision_tree     0  130   25  35  10  65.000000  12.500000   \n",
       "31        decision_tree     1  120   35  39   6  60.000000  17.500000   \n",
       "32        decision_tree     2  119   36  32  13  59.500000  18.000000   \n",
       "33        decision_tree     3  126   28  32  13  63.316583  14.070352   \n",
       "34        decision_tree     4  126   28  33  12  63.316583  14.070352   \n",
       "35          naive_bayes     0   32  123   7  38  16.000000  61.500000   \n",
       "36          naive_bayes     1   88   67  27  18  44.000000  33.500000   \n",
       "37          naive_bayes     2   28  127   9  36  14.000000  63.500000   \n",
       "38          naive_bayes     3   20  134   8  37  10.050251  67.336683   \n",
       "39          naive_bayes     4   16  138   2  43   8.040201  69.346734   \n",
       "\n",
       "      perc_fn    perc_tp  ...    recall       fpr  precision       ppv  \\\n",
       "0   20.000000   2.500000  ...  0.111111  0.064516   0.333333  0.333333   \n",
       "1   21.500000   1.000000  ...  0.044444  0.083871   0.133333  0.133333   \n",
       "2   18.500000   4.000000  ...  0.177778  0.161290   0.242424  0.242424   \n",
       "3   18.592965   4.020101  ...  0.177778  0.136364   0.275862  0.275862   \n",
       "4   21.105528   1.507538  ...  0.066667  0.103896   0.157895  0.157895   \n",
       "5   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "6   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "7   22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "8   22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "9   22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "10  21.500000   1.000000  ...  0.044444  0.070968   0.153846  0.153846   \n",
       "11  21.500000   1.000000  ...  0.044444  0.051613   0.200000  0.200000   \n",
       "12  19.500000   3.000000  ...  0.133333  0.116129   0.250000  0.250000   \n",
       "13  20.603015   2.010050  ...  0.088889  0.045455   0.363636  0.363636   \n",
       "14  21.608040   1.005025  ...  0.044444  0.058442   0.181818  0.181818   \n",
       "15  22.500000   0.000000  ...  0.000000  0.019355   0.000000  0.000000   \n",
       "16  21.500000   1.000000  ...  0.044444  0.012903   0.500000  0.500000   \n",
       "17  20.500000   2.000000  ...  0.088889  0.045161   0.363636  0.363636   \n",
       "18  21.608040   1.005025  ...  0.044444  0.038961   0.250000  0.250000   \n",
       "19  22.110553   0.502513  ...  0.022222  0.058442   0.100000  0.100000   \n",
       "20  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "21  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "22  22.500000   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "23  22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "24  22.613065   0.000000  ...  0.000000  0.000000        NaN       NaN   \n",
       "25  21.500000   1.000000  ...  0.044444  0.103226   0.111111  0.111111   \n",
       "26  17.500000   5.000000  ...  0.222222  0.174194   0.270270  0.270270   \n",
       "27  19.500000   3.000000  ...  0.133333  0.064516   0.375000  0.375000   \n",
       "28  18.090452   4.522613  ...  0.200000  0.142857   0.290323  0.290323   \n",
       "29  18.592965   4.020101  ...  0.177778  0.175325   0.228571  0.228571   \n",
       "30  17.500000   5.000000  ...  0.222222  0.161290   0.285714  0.285714   \n",
       "31  19.500000   3.000000  ...  0.133333  0.225806   0.146341  0.146341   \n",
       "32  16.000000   6.500000  ...  0.288889  0.232258   0.265306  0.265306   \n",
       "33  16.080402   6.532663  ...  0.288889  0.181818   0.317073  0.317073   \n",
       "34  16.582915   6.030151  ...  0.266667  0.181818   0.300000  0.300000   \n",
       "35   3.500000  19.000000  ...  0.844444  0.793548   0.236025  0.236025   \n",
       "36  13.500000   9.000000  ...  0.400000  0.432258   0.211765  0.211765   \n",
       "37   4.500000  18.000000  ...  0.800000  0.819355   0.220859  0.220859   \n",
       "38   4.020101  18.592965  ...  0.822222  0.870130   0.216374  0.216374   \n",
       "39   1.005025  21.608040  ...  0.955556  0.896104   0.237569  0.237569   \n",
       "\n",
       "    specificity       tnr  f1_score       auc     kappa  accuracy  \n",
       "0      0.935484  0.935484  0.166667  0.523297  0.061033  0.750000  \n",
       "1      0.916129  0.916129  0.066667  0.480287 -0.051643  0.720000  \n",
       "2      0.838710  0.838710  0.205128  0.508244  0.018211  0.690000  \n",
       "3      0.863636  0.863636  0.216216  0.520707  0.047375  0.708543  \n",
       "4      0.896104  0.896104  0.093750  0.481385 -0.046798  0.708543  \n",
       "5      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "6      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "7      1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "8      1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "9      1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "10     0.929032  0.929032  0.068966  0.486738 -0.035475  0.730000  \n",
       "11     0.948387  0.948387  0.072727  0.496416 -0.009901  0.745000  \n",
       "12     0.883871  0.883871  0.173913  0.508602  0.020619  0.715000  \n",
       "13     0.954545  0.954545  0.142857  0.521717  0.059287  0.758794  \n",
       "14     0.941558  0.941558  0.071429  0.493001 -0.019106  0.738693  \n",
       "15     0.980645  0.980645       NaN  0.490323 -0.028939  0.760000  \n",
       "16     0.987097  0.987097  0.081633  0.515771  0.046610  0.775000  \n",
       "17     0.954839  0.954839  0.142857  0.521864  0.059745  0.760000  \n",
       "18     0.961039  0.961039  0.075472  0.502742  0.007734  0.753769  \n",
       "19     0.941558  0.941558  0.036364  0.481890 -0.049975  0.733668  \n",
       "20     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "21     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "22     1.000000  1.000000       NaN  0.500000  0.000000  0.775000  \n",
       "23     1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "24     1.000000  1.000000       NaN  0.500000  0.000000  0.773869  \n",
       "25     0.896774  0.896774  0.063492  0.470609 -0.074681  0.705000  \n",
       "26     0.825806  0.825806  0.243902  0.524014  0.051262  0.690000  \n",
       "27     0.935484  0.935484  0.196721  0.534409  0.089219  0.755000  \n",
       "28     0.857143  0.857143  0.236842  0.528571  0.064213  0.708543  \n",
       "29     0.824675  0.824675  0.200000  0.501227  0.002662  0.678392  \n",
       "30     0.838710  0.838710  0.250000  0.530466  0.066148  0.700000  \n",
       "31     0.774194  0.774194  0.139535  0.453763 -0.095485  0.630000  \n",
       "32     0.767742  0.767742  0.276596  0.528315  0.054899  0.660000  \n",
       "33     0.818182  0.818182  0.302326  0.553535  0.110548  0.698492  \n",
       "34     0.818182  0.818182  0.282353  0.542424  0.088321  0.693467  \n",
       "35     0.206452  0.206452  0.368932  0.525448  0.026582  0.350000  \n",
       "36     0.567742  0.567742  0.276923  0.483871 -0.024523  0.530000  \n",
       "37     0.180645  0.180645  0.346154  0.490323 -0.010026  0.320000  \n",
       "38     0.129870  0.129870  0.342593  0.476046 -0.024063  0.286432  \n",
       "39     0.103896  0.103896  0.380531  0.529726  0.028727  0.296482  \n",
       "\n",
       "[40 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_2 = pd.DataFrame(resultados_2)\n",
    "df_resultados_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218eb0d-98e3-454f-bf6f-3ca9e95045a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
